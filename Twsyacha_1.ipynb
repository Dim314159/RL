{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5342f1d-9d04-41ee-889e-c1d3e7492918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "import sys\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b02e4f-ecb6-40e4-a376-2f55bde7b6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a349853-79e1-4a25-aeb8-7e8005afb23f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d5b11-a46c-4ae9-9292-c996f401cad1",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d48f8ca-cddd-4327-89a6-9dd6a36ec7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, heads):\n",
    "        super().__init__()\n",
    "        self.d_hid = d_hid\n",
    "        self.heads = heads\n",
    "        self.dim_per_head = self.d_hid // self.heads\n",
    "        \n",
    "        self.qkv = nn.Linear(d_emb, self.d_hid * 3, bias = False)\n",
    "        \n",
    "        \n",
    "        self.unifyheads = nn.Linear(self.d_hid, d_emb)\n",
    "    \n",
    "    def self_attention(self, q, k, v):\n",
    "        scores = torch.einsum('...ij,...kj->...ik', q, k) / np.sqrt(self.dim_per_head)\n",
    "        scores = F.softmax(scores, dim = -1)\n",
    "        return torch.einsum('...ij,...jk->...ik', scores, v)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        qkv = self.qkv(x)\n",
    "        q = qkv[..., :self.d_hid]\n",
    "        k = qkv[..., self.d_hid : self.d_hid * 2]\n",
    "        v = qkv[..., self.d_hid * 2 :]\n",
    "            \n",
    "        q = rearrange(q, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        k = rearrange(k, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        v = rearrange(v, '... i (h j) -> ... h i j', h = self.heads)\n",
    "                \n",
    "        scores = self.self_attention(q, k, v)\n",
    "        scores = rearrange(scores, '... h i j -> ... i (h j)').contiguous()\n",
    "                \n",
    "        return self.unifyheads(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5e0976-938f-423c-97c5-8117e837b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.out_size = out_size\n",
    "        self.linear = nn.Linear(in_size, out_size * 2)\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        #x = x[..., : self.out_size] * x[..., self.out_size :].sigmoid()\n",
    "        x = torch.einsum('...i, ...i->...i', [x[..., : self.out_size], x[..., self.out_size :].sigmoid()])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7e144d-ee91-40ff-b73f-e82d7a3f4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_layer(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, hidden_mult, heads, enc_drop):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(enc_drop)\n",
    "        \n",
    "        self.mha = Multi_Head_Attention(d_emb, d_hid, heads)\n",
    "        self.norm_1 = nn.LayerNorm(d_emb)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_emb, hidden_mult * d_emb),\n",
    "            #nn.ReLU(),\n",
    "            #nn.GELU(),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_mult * d_emb, d_emb)\n",
    "        )\n",
    "        #self.ff = GLU(d_emb, d_emb)\n",
    "        \n",
    "        self.norm_2 = nn.LayerNorm(d_emb)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attended = self.mha(x)\n",
    "        x = attended + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_1(x)\n",
    "        fed_for = self.ff(x)\n",
    "        x = fed_for + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3cb18ac-a39a-4fdc-a939-2138b6fdcf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, model_hp):\n",
    "        super().__init__()\n",
    "        self.epochs = 0\n",
    "        self.losses = []\n",
    "        \n",
    "        d_emb, hidden_mult, order, enc_drop, lr = model_hp\n",
    "        self.d_emb = d_emb\n",
    "        \n",
    "        d_score = 1\n",
    "        d_barrier = 4\n",
    "        seq_length = 5\n",
    "        \n",
    "        # self.score_emb = GLU(d_score, d_score * d_emb)\n",
    "        # self.temp_score_emb = GLU(1, d_emb)\n",
    "        self.score_emb = nn.Linear(1, d_emb)\n",
    "        self.temp_score_emb = nn.Linear(1, d_emb)\n",
    "        self.dice_emb = nn.Embedding(6, d_emb)\n",
    "        self.barrier_emb = nn.Embedding(d_barrier, d_emb)\n",
    "        \n",
    "        self.sr_d_emb = np.sqrt(d_emb)\n",
    "        \n",
    "        self.cls_token = nn.Parameter(torch.rand(1, d_emb))\n",
    "        self.pe = nn.Parameter(torch.rand(seq_length, d_emb))\n",
    "                \n",
    "        self.encoder = nn.ModuleList()\n",
    "        for d_hid, heads in order:\n",
    "            self.encoder.append(Encoder_layer(d_emb, d_hid, hidden_mult, heads, enc_drop))\n",
    "        \n",
    "        #self.out = GLU(self.d_emb, 2)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(self.d_emb, self.d_emb * 2),\n",
    "            #nn.ReLU(),\n",
    "            #nn.GELU(),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.d_emb * 2, 2)\n",
    "        )\n",
    "                \n",
    "        #self.weights_init()\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr = lr)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # if torch.cuda.is_available():\n",
    "        #     torch.cuda.set_device(cuda)\n",
    "        #     self.device = torch.device('cuda')\n",
    "        # else:\n",
    "        #     self.device = torch.device('cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                #nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.normal_(m.weight, mean = 0, std = 0.01)\n",
    "                #m.bias.data.fill_(0.01)\n",
    "         \n",
    "    def forward(self, s, ts, d, b):\n",
    "        s = self.score_emb(s)\n",
    "        s = rearrange(s, '... (s e) -> ... s e', e = self.d_emb)\n",
    "        ts = self.temp_score_emb(ts)#[None]\n",
    "        ts = rearrange(ts, '... (s e) -> ... s e', e = self.d_emb)\n",
    "        d = self.dice_emb(d)\n",
    "        b = self.barrier_emb(b)\n",
    "        \n",
    "        x = torch.cat((s, ts, d, b), dim = -2)\n",
    "        \n",
    "        cls_toks = repeat(self.cls_token, 's e -> b s e', b = x.size(0))\n",
    "        x = torch.cat((cls_toks, x), dim = 1)\n",
    "        x = x * self.sr_d_emb + self.pe #[:x.size(1)]\n",
    "        print(x.shape)\n",
    "        for enc in self.encoder:\n",
    "            x = enc(x)\n",
    "        x = x[:, 0]\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb5a62-0457-4243-bb30-853b7dcf55b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a9986-b4a9-4697-a9d3-3ba18a5bcde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6a07bcb-8b49-41b7-a4e3-a3abbdaf1561",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9774515b-9712-4c91-9654-b346ad450d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, model_hp, capacity):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = Transformer(model_hp)\n",
    "        self.replay_history = Replay_history(capacity)\n",
    "        self.age = 0\n",
    "        \n",
    "        self.me_score = 0\n",
    "        self.n_dice = 5\n",
    "        self.barrier = 0\n",
    "        self.roll = []\n",
    "        self.tempo_score = 0\n",
    "        self.n_turns = 0\n",
    "    \n",
    "    def refresh(self):\n",
    "        self.me_score = 0\n",
    "        self.n_dice = 5\n",
    "        self.barrier = 0\n",
    "        self.roll = []\n",
    "        self.tempo_score = 0\n",
    "        self.n_turns = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afeaca67-0453-4ab8-8069-9e9e40d47b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Replay_history():\n",
    "    def __init__(self, capacity):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.buffer = []\n",
    "        self.reward = -1\n",
    "        self.capacity = capacity\n",
    "        self.history = []\n",
    "        \n",
    "    def fill_buffer(self, state, action, done):\n",
    "        self.buffer.append(np.hstack([state, action, done]))\n",
    "    \n",
    "    def fill_history(self):\n",
    "        new_length = len(self.history) + len(self.buffer)\n",
    "        if new_length > self.capacity:\n",
    "            del self.history[: new_length - self.capacity]\n",
    "            r = self.reward / len(self.buffer)\n",
    "            for b in self.buffer:\n",
    "                b.append(r)\n",
    "            self.history.extend(self.buffer)\n",
    "            self.buffer = []\n",
    "        \n",
    "    def get_batch(self, batch):\n",
    "        indices = np.random.choice(len(self.history), batch, replace = False)\n",
    "        return np.asarray(self.buffer)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7968da5e-d6a0-451c-923b-5a941bd3eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_roll(agent):\n",
    "    agent.roll = np.random.randint(6, size = agent.n_dice)\n",
    "    count = np.unique(agent.roll, return_counts = True)\n",
    "    summ = 0\n",
    "    for d, c in zip(count[0], count[1]):\n",
    "        if c == 5:\n",
    "            if d == 0:\n",
    "                summ += 400\n",
    "            elif d == 4:\n",
    "                summ += 200\n",
    "            else:\n",
    "                summ += 120\n",
    "            agent.n_dice = agent.n_dice - c\n",
    "        elif c == 4:\n",
    "            if d == 0:\n",
    "                summ += 200\n",
    "            elif d == 4:\n",
    "                summ += 100\n",
    "            else:\n",
    "                summ += 60\n",
    "            agent.n_dice = agent.n_dice - c\n",
    "        elif c == 3:\n",
    "            if d == 0:\n",
    "                summ += 100\n",
    "            elif d == 4:\n",
    "                summ += 50\n",
    "            else:\n",
    "                summ += 30\n",
    "            agent.n_dice = agent.n_dice - c\n",
    "        else:\n",
    "            if d == 0:\n",
    "                summ += 10 * c\n",
    "                agent.n_dice = agent.n_dice - c\n",
    "            elif d == 4:\n",
    "                summ += 5 * c\n",
    "                agent.n_dice = agent.n_dice - c\n",
    "        if agent.n_dice == 0:\n",
    "            agent.n_dice = 5\n",
    "            break\n",
    "    if summ == 0:\n",
    "        agent.tempo_score = 0\n",
    "        return False\n",
    "    else:\n",
    "        agent.tempo_score = agent.tempo_score + summ\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42cd631b-20ee-4b69-aee9-95fea3dac210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL\n",
    "def turn(agent, epsilon, max_turns):\n",
    "    while True:\n",
    "        agent.n_turns += 1\n",
    "        if agent.n_turns == max_turns:\n",
    "            return 0\n",
    "        flag = make_roll(agent)\n",
    "        if flag:\n",
    "            score = agent.me_score + agent.tempo_score\n",
    "            if score >= 1000:\n",
    "                agent.me_score = score\n",
    "                agent.buffer[-1][-1] = 1\n",
    "                return 0\n",
    "            if (score > 395 and score < 500) or (score > 895 and score < 1000):\n",
    "                if agent.barrier == 0:\n",
    "                    agent.barrier = 1\n",
    "                elif agent.barrier == 2:\n",
    "                    continue\n",
    "            else:\n",
    "                if agent.barrier == 2:\n",
    "                    agent.barrier = 3\n",
    "                else:\n",
    "                    agent.barrier = 0\n",
    "            s = torch.tensor([[agent.me_score / 1000]], dtype = torch.float, device = agent.net.device)\n",
    "            ts = torch.tensor([[agent.tempo_score / 1000]], dtype = torch.float, device = agent.net.device)\n",
    "            d = torch.tensor([[agent.n_dice]], dtype = torch.long, device = agent.net.device)\n",
    "            b = torch.tensor([[agent.barrier]], dtype = torch.long, device = agent.net.device)\n",
    "            out = agent.net(s, ts, d, b)\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = torch.argmax(out).item()\n",
    "            else:\n",
    "                action = np.random.choice([0, 1])\n",
    "            agent.replay_history.fill_buffer([agent.me_score, agent.tempo_score, agent.n_dice, agent.barrier], action, 0)\n",
    "            if action:\n",
    "                continue\n",
    "            else:\n",
    "                agent.me_score = agent.me_score + agent.tempo_score\n",
    "                agent.tempo_score = 0\n",
    "                flag_done = True\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    agent.n_dice = 5\n",
    "    if (agent.me_score > 395 and agent.me_score < 500) or (agent.me_score > 895 and agent.me_score < 1000):\n",
    "        agent.barrier = 2\n",
    "    else:\n",
    "        agent.barrier = 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441e660-a2ca-4193-8300-f111b9860278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def game(agent, epsilon max_turns = 100):\n",
    "    agent.refresh()\n",
    "    while turn(agent, epsilon, max_turns)\n",
    "        agent.replay_history.fill_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91d248-1614-4d8c-8343-995634ebe9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbef86-f641-413b-bbe4-9b3716699602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbfdbd-17c6-407c-a33f-159d4be7fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9c6d19a-42b7-46a3-9d5d-fba79d75afa8",
   "metadata": {},
   "source": [
    "## Agents parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c54a6b88-03c6-448e-bfd2-c676e5568abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_emb = 8\n",
    "#seq_length = 6\n",
    "hidden_mult = 4\n",
    "# order = [(128, 8), (128, 8), \n",
    "#          (64, 4), (64, 4), \n",
    "#          (64, 2), (64, 2), \n",
    "#          (32, 1), (32, 1)]\n",
    "order = [(32, 4), (32, 4), (32, 2), (32, 2), (32, 1), (32, 1)]\n",
    "#heads_order = [1] * 12\n",
    "enc_drop = 0.05  # 0.005\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0b3ca77-4eef-4e63-971c-ab825baaa0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hp = d_emb, hidden_mult, order, enc_drop, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "496ed472-b740-4a5a-9d09-8a3c39c18d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(model_hp)\n",
    "print('num of parameters:', sum(p.numel() for p in agent.net.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f4b36d96-c166-4e56-b04a-36cbcaebe444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f03d9e-f880-4aec-84ca-69850dd816c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda27c7a-62a5-47b1-a6d8-2e019decb92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283b38b-2f1c-4bd6-83ea-3b54f1046ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07304eb2-4c5b-4aea-a50a-1af1e0797674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b1b7d-5ada-4380-ac46-d487e055cf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec36616-bcd0-4e27-a0db-b865b04f7d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa8a54-946d-4742-b499-5aa125ab0318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb375f64-2b63-44ea-bbec-93aaf949f78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db4476-8de0-41c0-a001-6a4646f0de28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42d2ef-b78c-4345-a142-f142e175ea04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fe8e916c-24fc-4d18-b96d-f8dde864e054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "55134c0b-e111-4958-88b0-38477827379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "66f1224a-6836-4f1f-ba96-fd1519af8c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a08f3e69-4e51-471e-834a-38099bd6232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] 35 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce1d53-6b6a-4916-8adb-39aad2779175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e1b0d-3e69-4f76-be77-86aa14fcd4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab4a6e-24b5-47ab-9067-f0725598853f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b823df-1c79-49d0-bfc8-8d37a390f119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991547e-279d-4dc3-bde7-5a29da123f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444510ca-84b6-4816-81be-cf1957a8d8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53737db-edd5-4514-9fd7-ae40926d1fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e3f65-575f-4897-a351-411515f7053a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33abcf4-307e-4f14-a88f-955db74eb3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db128f-2883-4215-8f21-0a8121f5ec49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6a701-81b5-4481-85a0-39a7d5235bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc5fea-6b70-4bc4-a264-de25584ae729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91bdd77-d537-4798-bcd4-ac0baba40bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7a6d5-29de-4ac8-9eaa-69b6ecb43cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3b9e46d-ac2d-4dba-a6bb-27b5d923dc39",
   "metadata": {},
   "source": [
    "# WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d9651f42-9d58-43e1-928a-e422fdb3e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = nn.Embedding(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f3385-f7ed-4e1f-815e-c99dae4ae44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c7d00-3f19-4f66-b2a2-54ac0084f0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1dc64-3eca-4d11-835e-7a34626f375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchga\n",
    "import pygad\n",
    "\n",
    "def fitness_func(solution, sol_idx):\n",
    "    global data_inputs, data_outputs, torch_ga, model, loss_function\n",
    "\n",
    "    model_weights_dict = torchga.model_weights_as_dict(model=model,\n",
    "                                                         weights_vector=solution)\n",
    "\n",
    "    # Use the current solution as the model parameters.\n",
    "    model.load_state_dict(model_weights_dict)\n",
    "\n",
    "    predictions = model(data_inputs)\n",
    "\n",
    "    solution_fitness = 1.0 / (loss_function(predictions, data_outputs).detach().numpy() + 0.00000001)\n",
    "\n",
    "    return solution_fitness\n",
    "\n",
    "def callback_generation(ga_instance):\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
    "\n",
    "# Create the PyTorch model.\n",
    "input_layer  = torch.nn.Linear(2, 4)\n",
    "relu_layer = torch.nn.ReLU()\n",
    "dense_layer = torch.nn.Linear(4, 2)\n",
    "output_layer = torch.nn.Softmax(1)\n",
    "\n",
    "model = torch.nn.Sequential(input_layer,\n",
    "                            relu_layer,\n",
    "                            dense_layer,\n",
    "                            output_layer)\n",
    "# print(model)\n",
    "\n",
    "# Create an instance of the pygad.torchga.TorchGA class to build the initial population.\n",
    "torch_ga = torchga.TorchGA(model=model,\n",
    "                           num_solutions=10)\n",
    "\n",
    "loss_function = torch.nn.BCELoss()\n",
    "\n",
    "# XOR problem inputs\n",
    "data_inputs = torch.tensor([[0.0, 0.0],\n",
    "                            [0.0, 1.0],\n",
    "                            [1.0, 0.0],\n",
    "                            [1.0, 1.0]])\n",
    "\n",
    "# XOR problem outputs\n",
    "data_outputs = torch.tensor([[1.0, 0.0],\n",
    "                             [0.0, 1.0],\n",
    "                             [0.0, 1.0],\n",
    "                             [1.0, 0.0]])\n",
    "\n",
    "# Prepare the PyGAD parameters. Check the documentation for more information: https://pygad.readthedocs.io/en/latest/README_pygad_ReadTheDocs.html#pygad-ga-class\n",
    "num_generations = 250 # Number of generations.\n",
    "num_parents_mating = 5 # Number of solutions to be selected as parents in the mating pool.\n",
    "initial_population = torch_ga.population_weights # Initial population of network weights.\n",
    "\n",
    "# Create an instance of the pygad.GA class\n",
    "ga_instance = pygad.GA(num_generations=num_generations, \n",
    "                       num_parents_mating=num_parents_mating, \n",
    "                       initial_population=initial_population,\n",
    "                       fitness_func=fitness_func,\n",
    "                       on_generation=callback_generation)\n",
    "\n",
    "# Start the genetic algorithm evolution.\n",
    "ga_instance.run()\n",
    "\n",
    "# After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.\n",
    "ga_instance.plot_fitness(title=\"PyGAD & PyTorch - Iteration vs. Fitness\", linewidth=4)\n",
    "\n",
    "# Returning the details of the best solution.\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
    "print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n",
    "\n",
    "# Fetch the parameters of the best solution.\n",
    "best_solution_weights = torchga.model_weights_as_dict(model=model,\n",
    "                                                      weights_vector=solution)\n",
    "model.load_state_dict(best_solution_weights)\n",
    "predictions = model(data_inputs)\n",
    "print(\"Predictions : \\n\", predictions.detach().numpy())\n",
    "\n",
    "# Calculate the binary crossentropy for the trained model.\n",
    "print(\"Binary Crossentropy : \", loss_function(predictions, data_outputs).detach().numpy())\n",
    "\n",
    "# Calculate the classification accuracy of the trained model.\n",
    "a = torch.max(predictions, axis=1)\n",
    "b = torch.max(data_outputs, axis=1)\n",
    "accuracy = torch.sum(a.indices == b.indices) / len(data_outputs)\n",
    "print(\"Accuracy : \", accuracy.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83778c62-eec7-4b4c-9910-1c3a8a91762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten(flattened, shapes):\n",
    "    newarray = []\n",
    "    index = 0\n",
    "    for shape in shapes:\n",
    "        size = np.product(shape)\n",
    "        newarray.append(flattened[index : index + size].reshape(shape))\n",
    "        index += size\n",
    "    return newarray\n",
    "        \n",
    "def crossover(agents, network, pop_size):\n",
    "    offspring = []\n",
    "    for _ in range((pop_size - len(agents)) // 2):\n",
    "        parent1 = random.choice(agents)\n",
    "        parent2 = random.choice(agents)\n",
    "        child1 = Agent(network)\n",
    "        child2 = Agent(network)\n",
    "\n",
    "        shapes = [a.shape for a in parent1.neural_network.weights]\n",
    "\n",
    "        genes1 = np.concatenate([a.flatten() for a in parent1.neural_network.weights])\n",
    "        genes2 = np.concatenate([a.flatten() for a in parent2.neural_network.weights])\n",
    "\n",
    "        split = random.randint(0,len(genes1)-1)child1_genes = np.array(genes1[0:split].tolist() + genes2[split:].tolist())\n",
    "        child2_genes = np.array(genes1[0:split].tolist() + genes2[split:].tolist())\n",
    "\n",
    "        child1.neural_network.weights = unflatten(child1_genes,shapes)\n",
    "        child2.neural_network.weights = unflatten(child2_genes,shapes)\n",
    "\n",
    "        offspring.append(child1)\n",
    "        offspring.append(child2)\n",
    "    agents.extend(offspring)\n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3a6f8-1b85-4881-916d-2ecf10317884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ccd963-d90c-4dbb-8317-5a5b3d5a978c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f87813-dd72-4e3f-ba8b-996c85de4b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9ee569af-8aea-499e-b05f-94c709fc8c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22]),)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tempo = table_w > 1\n",
    "#torch.nonzero(table_w > 1, as_tuple = True)\n",
    "(table_w >= 0).nonzero(as_tuple = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4c8a8f6e-6ba6-4931-a26e-1423008665f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 15.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        -15.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "16afe294-1627-42d4-b313-8db3dc5c86e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  1,  4,  6,  4,  0,  3, 10, 12,  9,  2,  5,  3,  7,  8,  3, 10,  5,\n",
       "        12,  4, 13, 12,  8,  4])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = torch.randint(15, (24,))\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "adc0d124-53a1-41a5-81ba-30b8ac574fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 18, 20, 21])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = (tens > 11).nonzero().view(-1)\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "df2b86fb-25ca-424a-99b6-aed48066cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16, 17, 18, 19, 20, 21, 22, 23])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_inds = torch.arange(16, 24)\n",
    "ch_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3dbc7208-9be5-4711-a30e-6159bf5dccf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 18, 20, 21])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds[0] = 17\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0e3ea2ea-96ac-411a-ade8-89e6b452781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(inds > 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60696db-9789-4036-b249-e140ff4e2b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e91161-c512-4685-90bd-274c5c64e02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41098fcb-44f4-4355-8303-247532d73cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "91d5e18e-5c6e-4928-9ddc-88126b8c85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice_embedder(nn.Module):\n",
    "    def __init__(self, d_emb):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(6, d_emb)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        #x = rearrange(x, '... i j -> ... (i j)')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3b3d4cfa-84b1-478c-ba89-9015120433a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dice_embedder(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "945e2eee-c834-40d9-8cfb-a1684f24260a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll = torch.randint(6, (2,))\n",
    "roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a92187d4-8cf6-4090-83dd-9dc366efdf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 in roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f4c78a36-6744-4f14-8e1a-8ca88c34e844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "127522ff-e7b0-4d24-9291-20d13d5adbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5480, -0.9881,  0.6946, -1.4169]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(roll[:1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ec107e78-4d6b-442a-a485-82b8c43f72da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = torch.zeros(5,)\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fa9188ab-9209-4225-908e-6b87b93441b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.5480, -0.9881,  0.6946,\n",
       "        -1.4169], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((tens, result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18067c2f-b96e-4b61-b068-9ed12447d44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a66a32fb-0d01-417c-a848-ea001e5e7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, heads):\n",
    "        super().__init__()\n",
    "        self.d_hid = d_hid\n",
    "        self.heads = heads\n",
    "        self.dim_per_head = self.d_hid // self.heads\n",
    "        \n",
    "        self.qkv = nn.Linear(d_emb, self.d_hid * 3, bias = False)\n",
    "        \n",
    "        \n",
    "        self.unifyheads = nn.Linear(self.d_hid, d_emb)\n",
    "    \n",
    "    def self_attention(self, q, k, v):\n",
    "        scores = torch.einsum('...ij,...kj->...ik', q, k) / np.sqrt(self.dim_per_head)\n",
    "        scores = F.softmax(scores, dim = -1)\n",
    "        return torch.einsum('...ij,...jk->...ik', scores, v)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        qkv = self.qkv(x)\n",
    "        q = qkv[..., :self.d_hid]\n",
    "        k = qkv[..., self.d_hid : self.d_hid * 2]\n",
    "        v = qkv[..., self.d_hid * 2 :]\n",
    "            \n",
    "        q = rearrange(q, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        k = rearrange(k, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        v = rearrange(v, '... i (h j) -> ... h i j', h = self.heads)\n",
    "                \n",
    "        scores = self.self_attention(q, k, v)\n",
    "        scores = rearrange(scores, '... h i j -> ... i (h j)').contiguous()\n",
    "                \n",
    "        return self.unifyheads(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39cb920d-5841-4666-acaa-5a49191a49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.out_size = out_size\n",
    "        self.linear = nn.Linear(in_size, out_size * 2)\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        #x = x[..., : self.out_size] * x[..., self.out_size :].sigmoid()\n",
    "        x = torch.einsum('...i, ...i->...i', [x[..., : self.out_size], x[..., self.out_size :].sigmoid()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5a13c9e-5fe6-49f8-9abc-893201279156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_layer(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, hidden_mult, heads, enc_drop):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(enc_drop)\n",
    "        \n",
    "        self.mha = Multi_Head_Attention(d_emb, d_hid, heads)\n",
    "        self.norm_1 = nn.LayerNorm(d_emb)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_emb, hidden_mult * d_emb),\n",
    "            #nn.ReLU(),\n",
    "            #nn.GELU(),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_mult * d_emb, d_emb)\n",
    "        )\n",
    "        #self.ff = GLU(d_emb, d_emb)\n",
    "        \n",
    "        self.norm_2 = nn.LayerNorm(d_emb)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attended = self.mha(x)\n",
    "        x = attended + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_1(x)\n",
    "        fed_for = self.ff(x)\n",
    "        x = fed_for + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea011482-7d3c-4c36-a47d-798b39e32d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, model_hp):\n",
    "        super().__init__()\n",
    "        self.epochs = 0\n",
    "        self.losses = []\n",
    "        \n",
    "        d_emb, seq_length, hidden_mult, order, enc_drop, lr, cuda = model_hp\n",
    "        self.d_emb = d_emb\n",
    "        \n",
    "        self.score_emb = GLU(2, 2 * d_emb)\n",
    "        self.dice_emb = nn.Embedding(6, d_emb)\n",
    "        self.barrier_emb = nn.Embedding(2, d_emb)\n",
    "        \n",
    "        self.pe = nn.Parameter(torch.rand(seq_length + 1, d_emb))\n",
    "        self.cls_token = nn.Parameter(torch.rand(1, d_emb))\n",
    "        \n",
    "        self.encoder = nn.ModuleList()\n",
    "        for d_hid, heads in order:\n",
    "            self.encoder.append(Encoder_layer(d_emb, d_hid, hidden_mult, heads, enc_drop))\n",
    "        \n",
    "        self.out = GLU(self.d_emb, 2)\n",
    "                \n",
    "        self.weights_init()\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr = lr)\n",
    "        self.loss = nn.HuberLoss()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.set_device(cuda)\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                #m.bias.data.fill_(0.01)\n",
    "         \n",
    "    def forward(self, s, d, b):\n",
    "        s = self.score_emb(s)\n",
    "        s = rearrange(s, '... (s e) -> ... s e', e = self.d_emb)\n",
    "        d = self.dice_emb(d)\n",
    "        b = self.barrier_emb(b)\n",
    "        \n",
    "        x = torch.cat((s, d, b), dim = -2)\n",
    "        \n",
    "        cls_toks = repeat(self.cls_token, 's e -> b s e', b = x.size(0))\n",
    "        x = torch.cat((cls_toks, x), dim = 1)\n",
    "        x = x + self.pe #[:x.size(1)]\n",
    "        for enc in self.encoder:\n",
    "            x = enc(x)\n",
    "        x = x[:, 0]\n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba770f0b-beca-4240-96f4-80f9b9a7210a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822d1fc-4c7d-4e9c-95e5-77acf4277818",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e56641eb-ce66-43d9-a4d7-7878b11b4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(table, roll, action):\n",
    "    reward = 0\n",
    "    flag = False\n",
    "    roll = roll + 1\n",
    "    target = action + roll\n",
    "    if table[action] < 1:\n",
    "        reward -=2\n",
    "    elif target > 23 or table[target] < 0:\n",
    "        reward -= 1\n",
    "    else:\n",
    "        reward += table[action] / 6\n",
    "        flag = True\n",
    "    return reward, flag\n",
    "\n",
    "def get_reward_end(table, roll, action):\n",
    "    reward = 0\n",
    "    flag = False\n",
    "    roll = roll + 1\n",
    "    target = action + roll\n",
    "    if table[action] < 1:\n",
    "        reward -= 2\n",
    "    elif target > 23:\n",
    "        reward += 1\n",
    "        flag = True\n",
    "    elif table[target] < 0:\n",
    "        reward -= 1\n",
    "    else:\n",
    "        flag = True\n",
    "    return reward, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f74e1-1e44-4799-82f5-78cad4ef4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn(models, table, roll):\n",
    "    reward = 0\n",
    "    roll = torch.randint(6, (2,))\n",
    "    d = roll.to(device)\n",
    "    t = table.to(device)\n",
    "    chosen_actions = []\n",
    "    outs = []\n",
    "    out = models[0](t, d)\n",
    "    outs.append(out)\n",
    "    choice = out.argsort()[::-1]\n",
    "    for i, ch in enumerate(choice):\n",
    "        out = models[i + 1](t, d[ch : ch + 1])\n",
    "        spots = (table > 0).nonzero().view(-1)\n",
    "        actions = out.argsort()[::-1]\n",
    "        if torch.all(spots > 17):\n",
    "            for a in actions:\n",
    "                r, flag = get_reward_end(table, roll[choice], a)\n",
    "                reward += r\n",
    "                if flag:\n",
    "                    break\n",
    "            a = -1\n",
    "        else:\n",
    "            for a in actions:\n",
    "                r, flag = get_reward(table, roll[choice], a)\n",
    "                reward += r\n",
    "                if flag:\n",
    "                    break\n",
    "            a = -1\n",
    "        outs.append(out)\n",
    "        chosen_actions.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5d074-09b7-4956-bc61-36e5b57e116e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
