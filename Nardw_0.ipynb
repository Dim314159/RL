{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d5342f1d-9d04-41ee-889e-c1d3e7492918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import sys\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b02e4f-ecb6-40e4-a376-2f55bde7b6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a349853-79e1-4a25-aeb8-7e8005afb23f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e09bf62-2736-47ed-b6b8-5d997153a0df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## feed-forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3227d531-d0e1-42fa-95f1-44d6f31d699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice_embedder(nn.Module):\n",
    "    def __init__(self, d_emb):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(6, d_emb)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        #x = rearrange(x, '... i j -> ... (i j)')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "76354d2c-301d-4c07-a58a-8ec3719af7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table_embedder(nn.Module):\n",
    "    def __init__(self, drop):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(24, 16),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(16), \n",
    "            #nn.Dropout(drop),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(32), \n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(32, 24), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.LayerNorm(24))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "60324436-2c27-4a8d-b625-33de57ad2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Choose(nn.Module):\n",
    "    def __init__(self, d_emb, lr, drop):\n",
    "        super().__init__()\n",
    "        self.dice = Dice_embedder(d_emb)\n",
    "        self.table = Table_embedder(drop)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(24 + d_emb * 2, 32),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(32), \n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(16),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.LayerNorm(8),\n",
    "            nn.Linear(8, 2))\n",
    "    \n",
    "        self.weights_init()\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr = lr)\n",
    "        self.loss = nn.HuberLoss()\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward(self, t, d):\n",
    "        t = self.table(t)\n",
    "        d = self.dice(d)\n",
    "        td = torch.cat((t, d[0], d[1]))\n",
    "        out = self.out(td)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3f1b1cea-032f-471b-938f-544029600e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Move(nn.Module):\n",
    "    def __init__(self, d_emb, lr, drop):\n",
    "        super().__init__()\n",
    "        self.dice = Dice_embedder(d_emb)\n",
    "        self.table = Table(drop)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(24 + d_emb, 64),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(64), \n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(64),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.Linear(32, 24))\n",
    "                \n",
    "        self.weights_init()\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr = lr)\n",
    "        self.loss = nn.HuberLoss()\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward(self, t, d):\n",
    "        t = self.table(t)\n",
    "        d = self.dice(d)\n",
    "        td = torch.cat((t, d[0]))\n",
    "        out = self.out(td)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa1c6a-1db0-47eb-b58b-4561b12f0879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bb87219a-169e-4e8a-8c04-f458da64f4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5a29e088-149f-4db8-9d89-9742e2af2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_choose_w = Choose(4, 0.0001, 0.1)\n",
    "m_move1_w = Move(8, 0.0001, 0.1)\n",
    "m_move2_w = Move(8, 0.0001, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "11873579-4246-4f8c-aec2-26dbcba2cd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parameters: 3754\n",
      "num of parameters: 11392\n",
      "num of parameters: 11392\n"
     ]
    }
   ],
   "source": [
    "models = [m_choose_w, m_move1_w, m_move2_w]\n",
    "for m in models:\n",
    "    print('num of parameters:', sum(p.numel() for p in m.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d5b11-a46c-4ae9-9292-c996f401cad1",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "6d48f8ca-cddd-4327-89a6-9dd6a36ec7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, heads):\n",
    "        super().__init__()\n",
    "        self.d_hid = d_hid\n",
    "        self.heads = heads\n",
    "        self.dim_per_head = self.d_hid // self.heads\n",
    "        \n",
    "        self.qkv = nn.Linear(d_emb, self.d_hid * 3, bias = False)\n",
    "        \n",
    "        \n",
    "        self.unifyheads = nn.Linear(self.d_hid, d_emb)\n",
    "    \n",
    "    def self_attention(self, q, k, v):\n",
    "        scores = torch.einsum('...ij,...kj->...ik', q, k) / np.sqrt(self.dim_per_head)\n",
    "        scores = F.softmax(scores, dim = -1)\n",
    "        return torch.einsum('...ij,...jk->...ik', scores, v)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        qkv = self.qkv(x)\n",
    "        q = qkv[..., :self.d_hid]\n",
    "        k = qkv[..., self.d_hid : self.d_hid * 2]\n",
    "        v = qkv[..., self.d_hid * 2 :]\n",
    "            \n",
    "        q = rearrange(q, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        k = rearrange(k, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        v = rearrange(v, '... i (h j) -> ... h i j', h = self.heads)\n",
    "                \n",
    "        scores = self.self_attention(q, k, v)\n",
    "        scores = rearrange(scores, '... h i j -> ... i (h j)').contiguous()\n",
    "                \n",
    "        return self.unifyheads(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "7a5e0976-938f-423c-97c5-8117e837b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.out_size = out_size\n",
    "        self.linear = nn.Linear(in_size, out_size * 2)\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        #x = x[..., : self.out_size] * x[..., self.out_size :].sigmoid()\n",
    "        x = torch.einsum('...i, ...i->...i', [x[..., : self.out_size], x[..., self.out_size :].sigmoid()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "6d7e144d-ee91-40ff-b73f-e82d7a3f4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_layer(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, hidden_mult, heads, enc_drop):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(enc_drop)\n",
    "        \n",
    "        self.mha = Multi_Head_Attention(d_emb, d_hid, heads)\n",
    "        self.norm_1 = nn.LayerNorm(d_emb)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_emb, hidden_mult * d_emb),\n",
    "            #nn.ReLU(),\n",
    "            #nn.GELU(),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_mult * d_emb, d_emb)\n",
    "        )\n",
    "        #self.ff = GLU(d_emb, d_emb)\n",
    "        \n",
    "        self.norm_2 = nn.LayerNorm(d_emb)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attended = self.mha(x)\n",
    "        x = attended + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_1(x)\n",
    "        fed_for = self.ff(x)\n",
    "        x = fed_for + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "93b61d17-9a4b-42bc-93b0-163a8dc17557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, model_hp):\n",
    "        super().__init__()\n",
    "        self.epochs = 0\n",
    "        self.losses = []\n",
    "        \n",
    "        d_emb, seq_length, hidden_mult, order, enc_drop, d_toks, m_toks = model_hp\n",
    "        \n",
    "        self.sr_d_emb = np.sqrt(d_emb)\n",
    "        \n",
    "        self.dice_emb = nn.Embedding(6, d_emb)\n",
    "        self.table_emb = nn.Embedding(31, d_emb)\n",
    "        \n",
    "        self.cls_toks = d_toks + m_toks * 2\n",
    "        self.pe = nn.Parameter(torch.rand(seq_length + self.cls_toks, d_emb))\n",
    "        self.cls_token = nn.Parameter(torch.rand(self.cls_toks, d_emb))\n",
    "        \n",
    "        self.encoder = nn.ModuleList()\n",
    "        for d_hid, heads in order:\n",
    "            self.encoder.append(Encoder_layer(d_emb, d_hid, hidden_mult, heads, enc_drop))\n",
    "        \n",
    "        self.out = nn.Linear(self.cls_toks * d_emb, 50)\n",
    "                \n",
    "        self.weights_init()\n",
    "        \n",
    "        \n",
    "    def weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight, gain = nn.init.calculate_gain('relu'))\n",
    "                #m.bias.data.fill_(0.01)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        d = x[..., :2]\n",
    "        t = x[..., 2:] + 15\n",
    "        d = self.dice_emb(d)\n",
    "        t = self.table_emb(t)\n",
    "        #x = rearrange(x, '... (s e) -> ... s e', e = self.d_emb)\n",
    "        cls_toks = repeat(self.cls_token, 's e -> b s e', b = d.size(0))\n",
    "        x = torch.cat((cls_toks, t, d), dim = 1)\n",
    "        x = x * self.sr_d_emb + self.pe #[:x.size(1)]\n",
    "        for enc in self.encoder:\n",
    "            x = enc(x)\n",
    "        #out = self.out(rearrange(x, 'i j k -> i (j k)'))\n",
    "        x = x[:, :self.cls_toks]\n",
    "        x = rearrange(x, '... s e -> ... (s e)')\n",
    "        x = self.out(x)\n",
    "        d = x[:, :2]\n",
    "        m1 = x[:, 2 : -24]\n",
    "        m2 = x[:, -24:]\n",
    "        #return F.softmax(d, dim = -1), F.softmax(m1, dim = -1), F.softmax(m2, dim = -1)\n",
    "        return d, m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb16f4a-7436-4877-ba6a-5c852898423c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a3eb7c6-caba-459e-8e21-fcf8b14aaff6",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "2711ca60-ec2c-44d2-8c5e-507d7116eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table():\n",
    "    def __init__(self):\n",
    "        self.phase = 0  # 0/1/2 -- game/house/done\n",
    "        self.state = np.zeros(24, dtype = int)\n",
    "        self.state[0] = 15\n",
    "        self.state[12] = -15\n",
    "        self.mine = {0}\n",
    "        self.his = {12}\n",
    "        self.home_cells = {6 : 18, 5 : 19, 4 : 20, 3 : 21, 2 : 22, 1 : 23}\n",
    "    \n",
    "    def check_phase(self):\n",
    "        if self.phase == 0:\n",
    "            condition = lambda x : x > 17\n",
    "            if all(condition(x) for x in self.mine):\n",
    "                self.phase = 1\n",
    "        elif self.phase == 1:\n",
    "            if not self.mine:\n",
    "                self.phase = 2\n",
    "    \n",
    "    def get_legal_actions(self, die, flag_head):\n",
    "        die += 1\n",
    "        legal_actions = np.zeros(24)\n",
    "        if self.phase == 1:\n",
    "            flag_out = True\n",
    "            tempo_actions = []\n",
    "            for p in range(6, die - 1, -1):\n",
    "                if self.home_cells[p] in self.mine:\n",
    "                    tempo_actions.append(p)\n",
    "                    flag_out = False\n",
    "            if flag_out:\n",
    "                legal_actions[list(self.mine)] = 1\n",
    "            else:\n",
    "                for p in tempo_actions:\n",
    "                    if (self.home_cells[p] + die > 23) or (self.home_cells[p - die] not in self.his):\n",
    "                        legal_actions[self.home_cells[p]] = 1\n",
    "        elif self.phase == 0:\n",
    "            for p in self.mine:\n",
    "                destination = p + die\n",
    "                if (destination < 24) and (destination not in self.his):\n",
    "                    if destination < 12 and destination not in self.mine:\n",
    "                        new_mine = self.mine | {destination}\n",
    "                        if not self.check_mars(new_mine):\n",
    "                            legal_actions[p] = 1\n",
    "                    else:\n",
    "                        legal_actions[p] = 1\n",
    "            if flag_head:\n",
    "                legal_actions[0] = 0\n",
    "        return legal_actions.astype(bool)\n",
    "    \n",
    "    def check_mars(self, new_mine):\n",
    "        n = 6\n",
    "        mars_end = 0\n",
    "        for i in range(7):\n",
    "            if all(j in new_mine for j in range(i, i + n)):\n",
    "                mars_end = i + n\n",
    "        if mars_end:\n",
    "            for i in range(mars_end, 12):\n",
    "                if i in self.his:\n",
    "                    return False\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def update(self, action, die, me):\n",
    "        die += 1\n",
    "        if me:\n",
    "            destination = action + die\n",
    "            self.state[action] -= 1\n",
    "            if self.state[action] < 1:\n",
    "                self.mine.remove(action)\n",
    "            if destination < 24:\n",
    "                self.state[destination] += 1\n",
    "                self.mine.add(destination)\n",
    "        else:\n",
    "            destination = action + die\n",
    "            action = (action + 12) % 24\n",
    "            self.state[action] += 1\n",
    "            if self.state[action] > -1:\n",
    "                self.his.remove(action)\n",
    "            if destination < 24:\n",
    "                destination = (destination + 12) % 24\n",
    "                self.state[destination] -= 1\n",
    "                self.his.add(destination)\n",
    "    \n",
    "    def print_table(self):\n",
    "        row_format = '{:>6}' * 13\n",
    "        print(row_format.format('', *self.state[11::-1]))\n",
    "        print(row_format.format('', *self.state[12:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "29e716d5-b09d-4207-96cd-cafbded14e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, model, model_hp, device):\n",
    "        super().__init__()\n",
    "        self.q_network = model(model_hp).to(device)\n",
    "        self.t_network = model(model_hp).to(device)\n",
    "        self.t_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.table = Table()\n",
    "        self.flag_first_turn = True\n",
    "        self.flag_done = False\n",
    "        self.flag_winner = False\n",
    "        self.memory_size = 2**13\n",
    "        self.buffer_size = 2**7\n",
    "        self.rep_memory = deque(maxlen = self.memory_size) #[2 dice,  24 table cells], size 26\n",
    "        self.act_memory = deque(maxlen = self.memory_size) #[die, move1, move1]\n",
    "        self.rew_memory = deque(maxlen = self.memory_size)\n",
    "        self.dice = None\n",
    "        self.epsilon = 0.5\n",
    "    \n",
    "    def refresh(self, reset = False):\n",
    "        self.table.phase = 0\n",
    "        self.flag_first_turn = True\n",
    "        self.flag_done = False\n",
    "        self.flag_winner = False\n",
    "        if reset:\n",
    "            self.rep_memory = []\n",
    "            self.act_memory = []\n",
    "            self.rew_memory = []\n",
    "    \n",
    "    def roll(self):\n",
    "        self.dice = list(np.random.randint(6, size = 2))\n",
    "    \n",
    "    def update_rep_memory(self):\n",
    "        self.rep_memory.append(np.concatenate((self.dice , self.table.state)))\n",
    "    def update_act_memory(self, d, m1, m2):\n",
    "        self.act_memory.append([d, m1, m2])\n",
    "    def update_rew_memory(self):\n",
    "        if not self.flag_first_turn:\n",
    "            if self.flag_done:\n",
    "                if self.flag_winner:\n",
    "                    r = 20\n",
    "                else:\n",
    "                    r = -20\n",
    "            else:\n",
    "                r = -1\n",
    "            self.rew_memory.append(r)\n",
    "    \n",
    "    def memory_not_full(self):\n",
    "        return len(self.rew_memory) != self.memory_size\n",
    "        \n",
    "    def num_parameters(self):\n",
    "        n = sum(p.numel() for p in self.q_network.parameters() if p.requires_grad)\n",
    "        print('number of parameters:', n)\n",
    "        \n",
    "    def calculate(self):\n",
    "        x = torch.LongTensor(self.rep_memory[-1]).to(device)\n",
    "        x = x.unsqueeze(0)\n",
    "        # d = x[..., :2]\n",
    "        # t = x[..., 2:] + 15\n",
    "        self.q_network.eval()\n",
    "        d, m1, m2 = self.q_network(x)\n",
    "        return d.detach().cpu()[0], m1.detach().cpu()[0], m2.detach().cpu()[0]\n",
    "    \n",
    "    def print_replay_memory(self):\n",
    "        row_format = '{:>6}' * 13\n",
    "        for i in range(len(self.rep_memory)):\n",
    "            print(row_format.format('', *self.rep_memory[i][13:1:-1]))\n",
    "            print(row_format.format('', *self.rep_memory[i][14:]))\n",
    "            print(self.rep_memory[i][:2] + 1)\n",
    "            print(self.act_memory[i])\n",
    "            print()\n",
    "    def train_the_agent(self, epochs, gamma, update_interval):\n",
    "        self.q_network.train()\n",
    "        self.t_network.eval()\n",
    "        for epoch in range(epochs):\n",
    "            indices = random.sample(range(self.memory_size - 1), self.buffer_size)\n",
    "            # Retrieve corresponding elements using the sampled indices\n",
    "            states = [self.rep_memory[i] for i in indices]\n",
    "            states = torch.tensor(np.vstack(states)).to(device)\n",
    "            next_states = [self.rep_memory[i + 1] for i in indices]\n",
    "            next_states = torch.tensor(np.vstack(next_states)).to(device)\n",
    "            actions = [self.act_memory[i] for i in indices]\n",
    "            actions = torch.tensor(actions).to(device)\n",
    "            rewards = [self.rew_memory[i] for i in indices]\n",
    "            rewards = torch.tensor(rewards).to(device)\n",
    "\n",
    "            d, m1, m2 = self.q_network(states)\n",
    "            q_d_values = d.gather(1, actions[:, 0].unsqueeze(1)).squeeze(1)\n",
    "            q_m1_values = m1.gather(1, actions[:, 1].unsqueeze(1)).squeeze(1)\n",
    "            q_m2_values = m2.gather(1, actions[:, 1].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            d, m1, m2 = self.t_network(states)\n",
    "            t_d_values = rewards + gamma * d.max(1)[0]\n",
    "            t_m1_values = rewards + gamma * m1.max(1)[0]\n",
    "            t_m2_values = rewards + gamma * m2.max(1)[0]\n",
    "\n",
    "            loss = self.criterion(torch.cat((q_d_values, q_m1_values, q_m2_values)), \n",
    "                                  torch.cat((t_d_values, t_m1_values, t_m2_values)))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if epoch % update_interval == 0:\n",
    "                self.t_network.load_state_dict(self.q_network.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "ae6236a9-03d9-4244-aac4-39cc75054704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn(agent, ag, flag_print = False):\n",
    "    if flag_print:\n",
    "        agent.table.print_table()\n",
    "    if agent.table.phase == 2:\n",
    "        if not agent.flag_done:\n",
    "            agent.flag_done = True\n",
    "            if not ag.flag_done:\n",
    "                agent.flag_winner = True\n",
    "            agent.update_rew_memory()\n",
    "    else:\n",
    "        agent.update_rew_memory()\n",
    "        agent.roll() # roll the dice\n",
    "        if flag_print:\n",
    "            print(' ' * 36, agent.dice[0] + 1, agent.dice[1] + 1)\n",
    "        agent.update_rep_memory()\n",
    "        d, m1, m2 = agent.calculate()\n",
    "        if agent.epsilon is not None:\n",
    "            if np.random.random() < agent.epsilon:\n",
    "                d = np.random.choice(dice_index)\n",
    "            else:\n",
    "                d = F.softmax(d, dim = -1).numpy()\n",
    "                d = np.random.choice(dice_index, p = d)\n",
    "        else:\n",
    "            d = F.softmax(d, dim = -1).numpy()\n",
    "            d = np.argmax(d)\n",
    "        d1 = agent.dice.pop(d)\n",
    "        d2 = agent.dice[0]\n",
    "        flag_head = False\n",
    "        mask = agent.table.get_legal_actions(d1, flag_head)\n",
    "        if mask.sum() > 0:\n",
    "            if agent.epsilon is not None:\n",
    "                if np.random.random() < agent.epsilon:\n",
    "                    m1 = np.random.choice(actions_index[mask])\n",
    "                else:\n",
    "                    m1 = F.softmax(m1[mask], dim = -1).numpy()\n",
    "                    m1 = np.random.choice(actions_index[mask], p = m1)\n",
    "            else:\n",
    "                m1 = F.softmax(m1[mask], dim = -1).numpy()\n",
    "                m1 = np.argmax(m1)\n",
    "            agent.table.update(m1, d1, True)\n",
    "            ag.table.update(m1, d1, False)\n",
    "            agent.table.check_phase()\n",
    "            if flag_print:\n",
    "                print('1st', m1, d1 + 1)\n",
    "                agent.table.print_table()\n",
    "        else:\n",
    "            m1 = -1\n",
    "            if flag_print:\n",
    "                print('no legal moves')\n",
    "        if agent.flag_first_turn:\n",
    "            agent.flag_first_turn = False\n",
    "        elif m1 == 0:\n",
    "            flag_head = True\n",
    "        mask = agent.table.get_legal_actions(d2, flag_head)\n",
    "        if mask.sum() > 0:\n",
    "            if agent.epsilon is not None:\n",
    "                if np.random.random() < agent.epsilon:\n",
    "                    m2 = np.random.choice(actions_index[mask])\n",
    "                else:\n",
    "                    m2 = F.softmax(m2[mask], dim = -1).numpy()\n",
    "                    m2 = np.random.choice(actions_index[mask], p = m2)\n",
    "            else:\n",
    "                m2 = F.softmax(m2[mask], dim = -1).numpy()\n",
    "                m2 = np.argmax(m2)\n",
    "            agent.table.update(m2, d2, True)\n",
    "            ag.table.update(m2, d2, False)\n",
    "            agent.table.check_phase()\n",
    "            if flag_print:\n",
    "                print('2nd', m2, d2 + 1)\n",
    "                agent.table.print_table()\n",
    "        else:\n",
    "            m2 = -1\n",
    "            if flag_print:\n",
    "                print('no legal moves')\n",
    "        agent.update_act_memory(d, m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "e7000c5c-3f7b-4b9f-9724-885e6afbb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def session(ag_1, ag_2):\n",
    "    ag_1.refresh(reset = False)\n",
    "    ag_2.refresh(reset = False)\n",
    "    while not (ag_1.flag_done and ag_2.flag_done):\n",
    "        turn(ag_1, ag_2)\n",
    "        turn(ag_2, ag_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057144a4-f170-4277-8edc-324618b3e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_the_replay_memory(ag_1, ag_2):\n",
    "    while ag_1.memory_not_full() or ag_2.memory_not_full():\n",
    "        session(ag_1, ag_2)\n",
    "        session(ag_2, ag_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "0100eccd-b61b-4039-bff1-921655ccc819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_train(ag_1, ag_2, num_games, train_interval, epochs, gamma, update_interval):\n",
    "    for i in range(num_games):\n",
    "        if i % train_interval == 0:\n",
    "            ag_1.train_the_agent(epochs, gamma, update_interval)\n",
    "            ag_1.train_the_agent(epochs, gamma, update_interval)\n",
    "        session(ag_1, ag_2)\n",
    "        session(ag_2, ag_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f9951-e729-45af-9056-6d569d9b4d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1250feee-0bf2-4414-ab2e-0a65353dc9c5",
   "metadata": {},
   "source": [
    "# Create agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "54e7d88f-baca-4272-8d35-e379898b5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "cuda_core = 0\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda_core)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "bdcbcef2-7b40-49f0-a5ff-3e69f8700fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "c54a6b88-03c6-448e-bfd2-c676e5568abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_index = np.arange(2)\n",
    "actions_index = np.arange(24)\n",
    "\n",
    "d_emb = 8\n",
    "seq_length = 26\n",
    "hidden_mult = 2\n",
    "# order = [(128, 8), (128, 8), \n",
    "#          (64, 4), (64, 4), \n",
    "#          (64, 2), (64, 2), \n",
    "#          (32, 1), (32, 1)]\n",
    "order = [(32, 4), (32, 4), (32, 2), (32, 2), (32, 1), (32, 1)]\n",
    "#heads_order = [1] * 12\n",
    "enc_drop = 0.05  # 0.005\n",
    "d_toks = 1\n",
    "m_toks = 2\n",
    "\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "a0b3ca77-4eef-4e63-971c-ab825baaa0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_hp = d_emb, seq_length, hidden_mult, order, enc_drop, d_toks, m_toks\n",
    "model = Transformer\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr = lr)\n",
    "# criterion = nn.HuberLoss()\n",
    "#print('num of parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "30aab82b-f4a4-4a96-87f0-938367058bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_1 = Agent(model, model1_hp, device)\n",
    "ag_1.optimizer = torch.optim.AdamW(ag_1.q_network.parameters(), lr = lr)\n",
    "ag_1.criterion = nn.MSELoss()\n",
    "ag_2 = Agent(model, model1_hp, device)\n",
    "ag_2.optimizer = torch.optim.AdamW(ag_2.q_network.parameters(), lr = lr)\n",
    "ag_2.criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9078b-52c5-43ee-904f-e3e08f96f307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "a73974a3-d916-485f-aabf-f22e16810bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start\n",
    "session(ag_1, ag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937e216-2eec-4e16-ad28-7ad2cbd4ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games, train_interval, epochs, gamma, update_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "2ea79a3a-755c-4ad7-af8e-50ef66b6ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('agent 1')\n",
    "# turn(ag_1, ag_2, flag_print = True)\n",
    "# print('\\nagent 2')\n",
    "# turn(ag_2, ag_1, flag_print = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fba8e-ba29-4c31-9d3d-f844b3c24828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "56ef071c-1e6c-4f95-82d1-d7ebf43e04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# states = torch.tensor(np.vstack(ag_1.rep_memory)).to(device)\n",
    "# next_states = torch.tensor(np.vstack(ag_1.rep_memory[1:11])).to(device)\n",
    "# actions = torch.tensor(ag_1.act_memory[:10]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "6cf776fd-7124-4ae4-a072-23a6d2b1d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(range(20 - 1), 8, replace = False)\n",
    "# Retrieve corresponding elements using the sampled indices\n",
    "states = [ag_1.rep_memory[i] for i in indices]\n",
    "states = torch.tensor(np.vstack(states)).to(device)\n",
    "next_states = [ag_1.rep_memory[i + 1] for i in indices]\n",
    "next_states = torch.tensor(np.vstack(next_states)).to(device)\n",
    "actions = [ag_1.act_memory[i] for i in indices]\n",
    "actions = torch.tensor(actions).to(device)\n",
    "rewards = [ag_1.rew_memory[i] for i in indices]\n",
    "rewards = torch.tensor(rewards).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5760dee-2f3c-42b9-984d-8f93e9f4fa9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "6b5ddcee-8a34-4276-bb26-55b408ea6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, m1, m2 = ag_1.q_network(states)\n",
    "q_d_values = d.gather(1, actions[:, 0].unsqueeze(1)).squeeze(1)\n",
    "q_m1_values = m1.gather(1, actions[:, 1].unsqueeze(1)).squeeze(1)\n",
    "q_m2_values = m2.gather(1, actions[:, 1].unsqueeze(1)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a499f-fb3e-419d-8437-2b745ac298ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "4fdce84f-bffd-4a29-b969-038ff9f8e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, m1, m2 = ag_1.t_network(next_states)\n",
    "t_d_values = rewards + gamma * d.max(1)[0]\n",
    "t_m1_values = rewards + gamma * m1.max(1)[0]\n",
    "t_m2_values = rewards + gamma * m2.max(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "b1f738c7-6f83-421f-b874-9078d08eaa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ag_1.criterion(torch.cat((q_d_values, q_m1_values, q_m2_values)), \n",
    "                    torch.cat((t_d_values, t_m1_values, t_m2_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "e351dfe7-5c28-45db-8eef-cc7a9147507f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6969, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "6cd14b24-0488-4443-96c3-38e2214ba4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0230, 1.0306, 1.3290, 1.9921, 1.6633, 1.7826, 2.1213, 2.7031],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_m1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "6341a8dc-a13b-4d14-a999-f823e42b60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e4405-2545-49b8-a21d-e2d522152e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f0b7a-2035-4d52-a3be-1085092cd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_the_agent(self, epochs, gamma, update_interval):\n",
    "    self.q_network.train()\n",
    "    self.t_network.eval()\n",
    "    for epoch in range(epochs)\n",
    "        indices = random.sample(range(self.memory_size - 1), self.buffer_size)\n",
    "        # Retrieve corresponding elements using the sampled indices\n",
    "        states = [self.rep_memory[i] for i in indices]\n",
    "        states = torch.tensor(np.vstack(states)).to(device)\n",
    "        next_states = [self.rep_memory[i + 1] for i in indices]\n",
    "        next_states = torch.tensor(np.vstack(next_states)).to(device)\n",
    "        actions = [self.act_memory[i] for i in indices]\n",
    "        actions = torch.tensor(actions).to(device)\n",
    "        rewards = [self.rew_memory[i] for i in indices]\n",
    "        rewards = torch.tensor(rewards).to(device)\n",
    "\n",
    "        d, m1, m2 = self.q_network(states)\n",
    "        q_d_values = d.gather(1, actions[:, 0].unsqueeze(1)).squeeze(1)\n",
    "        q_m1_values = m1.gather(1, actions[:, 1].unsqueeze(1)).squeeze(1)\n",
    "        q_m2_values = m2.gather(1, actions[:, 1].unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        d, m1, m2 = self.t_network(states)\n",
    "        t_d_values = rewards + gamma * d.max(1)[0]\n",
    "        t_m1_values = rewards + gamma * m1.max(1)[0]\n",
    "        t_m2_values = rewards + gamma * m2.max(1)[0]\n",
    "        \n",
    "        loss = self.criterion(torch.cat((q_d_values, q_m1_values, q_m2_values)), \n",
    "                              torch.cat((t_d_values, t_m1_values, t_m2_values)))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        if epoch % update_interval == 0:\n",
    "            self.t_network.load_state_dict(self.q_network.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae0a55-df84-4f67-8e05-5c8443977076",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rep_memory\n",
    "self.act_memory\n",
    "self.rew_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f643a2c6-a66e-4912-b5b5-9a147639b08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "25d884e1-8682-4937-88c5-34ec54822c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bbe1a-0184-431b-89bb-11efe7e4112d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abe579-667b-4e3a-8340-68cd149b1b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8964c1-46f7-4c45-8eb4-39319014b7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052cd39e-9cf6-45a7-8f85-bc2c5aa1cb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd3024-3e98-4355-bed4-34bd0cd59213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0daee97-f0bf-4071-8782-1d885106070b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703aff6f-289d-4815-9216-207819f08b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494a910-a47a-4aef-8baf-f749ac8d017f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4495eed-76da-4224-85df-90026ec41f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c42cc-5038-440b-914c-f40150443be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca56f1b-83a7-4e5a-8178-6979fc0a3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "# Define the replay buffer\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state'))\n",
    "replay_buffer = []\n",
    "\n",
    "# Define your Q-network\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the Q-network and target network\n",
    "input_dim = ...  # Dimensionality of your state\n",
    "output_dim = ...  # Number of possible actions\n",
    "q_network = QNetwork(input_dim, output_dim)\n",
    "target_network = QNetwork(input_dim, output_dim)\n",
    "target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "# Define other hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "discount_factor = 0.9\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Sample a mini-batch from the replay buffer\n",
    "    batch = random.sample(replay_buffer, batch_size)\n",
    "    state_batch = torch.stack([transition.state for transition in batch])\n",
    "    action_batch = torch.tensor([transition.action for transition in batch])\n",
    "    reward_batch = torch.tensor([transition.reward for transition in batch])\n",
    "    next_state_batch = torch.stack([transition.next_state for transition in batch])\n",
    "    \n",
    "    # Compute Q-values for the current state-action pairs using the Q-network\n",
    "    q_values = q_network(state_batch)\n",
    "    q_values = q_values.gather(1, action_batch.unsqueeze(1)).squeeze(1)\n",
    "    \n",
    "    # Compute the target Q-values for the next states using the target network\n",
    "    target_q_values = target_network(next_state_batch)\n",
    "    max_q_values = target_q_values.max(1)[0]\n",
    "    \n",
    "    # Compute the expected Q-values using the Q-learning update rule\n",
    "    expected_q_values = reward_batch + discount_factor * max_q_values\n",
    "    \n",
    "    # Compute the loss (e.g., mean squared error) between the predicted Q-values and the expected Q-values\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    \n",
    "    # Update the Q-network parameters\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update the target network parameters periodically\n",
    "    if epoch % target_update_interval == 0:\n",
    "        target_network.load_state_dict(q_network.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5404201-11ea-4dee-97e9-3f6c16b45b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd88a6-2147-40c3-a9b5-15a07d19d84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8224401-ecb2-45d5-974b-29fd08d94168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42d2ef-b78c-4345-a142-f142e175ea04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e404d60-067f-47f4-ae65-e309e73b822a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a4990-bd62-4f55-b073-3d411e182abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9dafa-70b1-4014-a4f1-5ae42598bbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c580986-5ec6-456e-9d2d-4663a47d242e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c60e6-a05e-4c2a-8e00-9d630254f8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff53134-1635-4b4f-a781-fadc532bc317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429b5be-ae90-40e7-a014-d6c566018f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723fd1f-567f-4c1c-92c8-c5e89537144f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc388c9-653e-4bb1-811c-d8ba146cabaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c7a42-9562-4fbf-a755-7a4e3b384ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d3368-902f-4dc3-9b1d-4ea3c25f8d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534ab4c-5c46-4cd9-93ed-c0db79a7bc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400616ef-78c5-4c49-83ff-4b53b1530f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a974d4-2699-4781-a157-8e473f9ff3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822d1fc-4c7d-4e9c-95e5-77acf4277818",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e56641eb-ce66-43d9-a4d7-7878b11b4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(table, roll, action):\n",
    "    reward = 0\n",
    "    flag = False\n",
    "    roll = roll + 1\n",
    "    target = action + roll\n",
    "    if table[action] < 1:\n",
    "        reward -=2\n",
    "    elif target > 23 or table[target] < 0:\n",
    "        reward -= 1\n",
    "    else:\n",
    "        reward += table[action] / 6\n",
    "        flag = True\n",
    "    return reward, flag\n",
    "\n",
    "def get_reward_end(table, roll, action):\n",
    "    reward = 0\n",
    "    flag = False\n",
    "    roll = roll + 1\n",
    "    target = action + roll\n",
    "    if table[action] < 1:\n",
    "        reward -= 2\n",
    "    elif target > 23:\n",
    "        reward += 1\n",
    "        flag = True\n",
    "    elif table[target] < 0:\n",
    "        reward -= 1\n",
    "    else:\n",
    "        flag = True\n",
    "    return reward, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f74e1-1e44-4799-82f5-78cad4ef4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn(models, table, roll):\n",
    "    reward = 0\n",
    "    roll = torch.randint(6, (2,))\n",
    "    d = roll.to(device)\n",
    "    t = table.to(device)\n",
    "    chosen_actions = []\n",
    "    outs = []\n",
    "    out = models[0](t, d)\n",
    "    outs.append(out)\n",
    "    choice = out.argsort()[::-1]\n",
    "    for i, ch in enumerate(choice):\n",
    "        out = models[i + 1](t, d[ch : ch + 1])\n",
    "        spots = (table > 0).nonzero().view(-1)\n",
    "        actions = out.argsort()[::-1]\n",
    "        if torch.all(spots > 17):\n",
    "            for a in actions:\n",
    "                r, flag = get_reward_end(table, roll[choice], a)\n",
    "                reward += r\n",
    "                if flag:\n",
    "                    break\n",
    "            a = -1\n",
    "        else:\n",
    "            for a in actions:\n",
    "                r, flag = get_reward(table, roll[choice], a)\n",
    "                reward += r\n",
    "                if flag:\n",
    "                    break\n",
    "            a = -1\n",
    "        outs.append(out)\n",
    "        chosen_actions.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991547e-279d-4dc3-bde7-5a29da123f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444510ca-84b6-4816-81be-cf1957a8d8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53737db-edd5-4514-9fd7-ae40926d1fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e3f65-575f-4897-a351-411515f7053a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33abcf4-307e-4f14-a88f-955db74eb3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db128f-2883-4215-8f21-0a8121f5ec49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6a701-81b5-4481-85a0-39a7d5235bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc5fea-6b70-4bc4-a264-de25584ae729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91bdd77-d537-4798-bcd4-ac0baba40bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7a6d5-29de-4ac8-9eaa-69b6ecb43cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3b9e46d-ac2d-4dba-a6bb-27b5d923dc39",
   "metadata": {},
   "source": [
    "# WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "78b51751-1e12-4a20-8c2f-f6246a8d83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mars(new_mine):\n",
    "    flag_mars = False\n",
    "    n = 6\n",
    "    for i in range(7):\n",
    "        if all(j in new_mine for j in range(i, i + n)):\n",
    "            flag_mars = True\n",
    "    return flag_mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "94bbe88c-1500-4f61-ad66-f5753cc255c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mine = {10, 8, 11, 6, 3, 1, 4, 5}\n",
    "check_mars(new_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab17e301-8787-4dba-b659-5b3b4c2b1e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "686a9db0-5dc7-4d31-9e95-5a9691947552",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9c8cde2-b686-4898-a07c-e4b29603a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.LongTensor([[0, 2], [1, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4aee4de7-ec59-483f-9e5a-1cec0c7a26d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2],\n",
       "        [1, 3]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26107466-6476-4e16-b37d-322251d075b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7558,  0.4006],\n",
       "         [-1.3213, -1.0613]],\n",
       "\n",
       "        [[ 0.2940, -1.1072],\n",
       "         [-1.1620, -1.4370]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a697a85-5812-4fe4-8496-55413eccc75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e488a-90d2-4131-b18e-d67870068271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aafca2-ea5c-4457-81d9-296190a84e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9ee569af-8aea-499e-b05f-94c709fc8c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22]),)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tempo = table_w > 1\n",
    "#torch.nonzero(table_w > 1, as_tuple = True)\n",
    "(table_w >= 0).nonzero(as_tuple = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4c8a8f6e-6ba6-4931-a26e-1423008665f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 15.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        -15.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "16afe294-1627-42d4-b313-8db3dc5c86e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  1,  4,  6,  4,  0,  3, 10, 12,  9,  2,  5,  3,  7,  8,  3, 10,  5,\n",
       "        12,  4, 13, 12,  8,  4])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = torch.randint(15, (24,))\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "adc0d124-53a1-41a5-81ba-30b8ac574fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 18, 20, 21])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = (tens > 11).nonzero().view(-1)\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "df2b86fb-25ca-424a-99b6-aed48066cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16, 17, 18, 19, 20, 21, 22, 23])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_inds = torch.arange(16, 24)\n",
    "ch_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3dbc7208-9be5-4711-a30e-6159bf5dccf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 18, 20, 21])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds[0] = 17\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0e3ea2ea-96ac-411a-ade8-89e6b452781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(inds > 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60696db-9789-4036-b249-e140ff4e2b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e91161-c512-4685-90bd-274c5c64e02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41098fcb-44f4-4355-8303-247532d73cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "91d5e18e-5c6e-4928-9ddc-88126b8c85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice_embedder(nn.Module):\n",
    "    def __init__(self, d_emb):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(6, d_emb)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        #x = rearrange(x, '... i j -> ... (i j)')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3b3d4cfa-84b1-478c-ba89-9015120433a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dice_embedder(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "945e2eee-c834-40d9-8cfb-a1684f24260a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll = torch.randint(6, (2,))\n",
    "roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a92187d4-8cf6-4090-83dd-9dc366efdf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 in roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f4c78a36-6744-4f14-8e1a-8ca88c34e844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "127522ff-e7b0-4d24-9291-20d13d5adbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5480, -0.9881,  0.6946, -1.4169]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(roll[:1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ec107e78-4d6b-442a-a485-82b8c43f72da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = torch.zeros(5,)\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fa9188ab-9209-4225-908e-6b87b93441b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.5480, -0.9881,  0.6946,\n",
       "        -1.4169], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((tens, result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18067c2f-b96e-4b61-b068-9ed12447d44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a66a32fb-0d01-417c-a848-ea001e5e7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, heads):\n",
    "        super().__init__()\n",
    "        self.d_hid = d_hid\n",
    "        self.heads = heads\n",
    "        self.dim_per_head = self.d_hid // self.heads\n",
    "        \n",
    "        self.qkv = nn.Linear(d_emb, self.d_hid * 3, bias = False)\n",
    "        \n",
    "        \n",
    "        self.unifyheads = nn.Linear(self.d_hid, d_emb)\n",
    "    \n",
    "    def self_attention(self, q, k, v):\n",
    "        scores = torch.einsum('...ij,...kj->...ik', q, k) / np.sqrt(self.dim_per_head)\n",
    "        scores = F.softmax(scores, dim = -1)\n",
    "        return torch.einsum('...ij,...jk->...ik', scores, v)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        qkv = self.qkv(x)\n",
    "        q = qkv[..., :self.d_hid]\n",
    "        k = qkv[..., self.d_hid : self.d_hid * 2]\n",
    "        v = qkv[..., self.d_hid * 2 :]\n",
    "            \n",
    "        q = rearrange(q, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        k = rearrange(k, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        v = rearrange(v, '... i (h j) -> ... h i j', h = self.heads)\n",
    "                \n",
    "        scores = self.self_attention(q, k, v)\n",
    "        scores = rearrange(scores, '... h i j -> ... i (h j)').contiguous()\n",
    "                \n",
    "        return self.unifyheads(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39cb920d-5841-4666-acaa-5a49191a49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.out_size = out_size\n",
    "        self.linear = nn.Linear(in_size, out_size * 2)\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        #x = x[..., : self.out_size] * x[..., self.out_size :].sigmoid()\n",
    "        x = torch.einsum('...i, ...i->...i', [x[..., : self.out_size], x[..., self.out_size :].sigmoid()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5a13c9e-5fe6-49f8-9abc-893201279156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_layer(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, hidden_mult, heads, enc_drop):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(enc_drop)\n",
    "        \n",
    "        self.mha = Multi_Head_Attention(d_emb, d_hid, heads)\n",
    "        self.norm_1 = nn.LayerNorm(d_emb)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_emb, hidden_mult * d_emb),\n",
    "            #nn.ReLU(),\n",
    "            #nn.GELU(),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_mult * d_emb, d_emb)\n",
    "        )\n",
    "        #self.ff = GLU(d_emb, d_emb)\n",
    "        \n",
    "        self.norm_2 = nn.LayerNorm(d_emb)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attended = self.mha(x)\n",
    "        x = attended + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_1(x)\n",
    "        fed_for = self.ff(x)\n",
    "        x = fed_for + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea011482-7d3c-4c36-a47d-798b39e32d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91aeb888-2f1e-4354-9dfd-20b38cd47850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, model_hp):\n",
    "        super().__init__()\n",
    "        self.epochs = 0\n",
    "        self.losses = []\n",
    "        \n",
    "        d_emb, seq_length, hidden_mult, order, enc_drop, d_toks, m1_toks, m2_toks = model_hp\n",
    "        self.d_toks = d_toks\n",
    "        self.m1_toks = m1_toks\n",
    "        self.m2_toks = m2_toks\n",
    "        self.d_emb = d_emb\n",
    "                \n",
    "        # self.emb = nn.Sequential(\n",
    "        #     nn.Linear(in_dim, in_dim * d_emb),\n",
    "        #     #nn.ReLU()\n",
    "        #     #nn.GELU()\n",
    "        #     nn.LeakyReLU()\n",
    "        # )\n",
    "        self.emb = GLU(seq_length, seq_length * d_emb)\n",
    "        \n",
    "        class_toks = d_toks + m1_toks + m2_toks\n",
    "        self.pe = nn.Parameter(torch.rand(seq_length + class_toks, d_emb))\n",
    "        self.cls_token = nn.Parameter(torch.rand(class_toks, d_emb))\n",
    "        \n",
    "        self.encoder = nn.ModuleList()\n",
    "        for d_hid, heads in order:\n",
    "            self.encoder.append(Encoder_layer(d_emb, d_hid, hidden_mult, heads, enc_drop))\n",
    "        \n",
    "        # self.out = nn.Sequential(\n",
    "        #     nn.Linear(d_emb, d_emb * 2),\n",
    "        #     #nn.ReLU(),\n",
    "        #     #nn.GELU(),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     #GLU(d_emb *, d_emb),\n",
    "        #     nn.Linear(d_emb * 2, num_classes)\n",
    "        # )\n",
    "        \n",
    "        self.out_d = GLU(d_emb * d_toks, 2)\n",
    "        self.out_m1 = GLU(d_emb * m1_toks, 24)\n",
    "        self.out_m2 = GLU(d_emb * m2_toks, 24)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = rearrange(x, '... (s e) -> ... s e', e = self.d_emb)\n",
    "        if self.cls_token_dim:\n",
    "            cls_toks = repeat(self.cls_token, 's e -> b s e', b = x.size(0))\n",
    "            x = torch.cat((cls_toks, x), dim = 1)\n",
    "        x = x + self.pe #[:x.size(1)]\n",
    "        for enc in self.encoder:\n",
    "            x = enc(x)\n",
    "        #out = self.out(rearrange(x, 'i j k -> i (j k)'))\n",
    "        if self.cls_token_dim:\n",
    "            m = x[:, :3]\n",
    "            d = x[:, 3]\n",
    "        else:\n",
    "            x = x.mean(dim = 1)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba770f0b-beca-4240-96f4-80f9b9a7210a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3cb18ac-a39a-4fdc-a939-2138b6fdcf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, model_hp):\n",
    "        super().__init__()\n",
    "        self.epochs = 0\n",
    "        self.losses = []\n",
    "        \n",
    "        d_emb, seq_length, hidden_mult, order, enc_drop, n_d_toks, n_m1_toks, n_m2_toks, lr, cuda = model_hp\n",
    "        self.n_d_toks = n_d_toks\n",
    "        self.n_m1_toks = n_m1_toks\n",
    "        self.n_m2_toks = n_m2_toks\n",
    "        self.d_emb = d_emb\n",
    "                \n",
    "        self.emb = GLU(seq_length, seq_length * d_emb)\n",
    "        \n",
    "        self.n_cls_toks = n_d_toks + n_m1_toks + n_m2_toks\n",
    "        self.pe = nn.Parameter(torch.rand(seq_length + self.n_cls_toks, d_emb))\n",
    "        self.cls_token = nn.Parameter(torch.rand(self.n_cls_toks, d_emb))\n",
    "        \n",
    "        self.encoder = nn.ModuleList()\n",
    "        for d_hid, heads in order:\n",
    "            self.encoder.append(Encoder_layer(d_emb, d_hid, hidden_mult, heads, enc_drop))\n",
    "        \n",
    "        self.n_out_d = d_emb * n_d_toks\n",
    "        self.out_d = GLU(self.n_out_d, 2)\n",
    "        self.n_out_m1 = d_emb * n_m1_toks\n",
    "        self.out_m1 = GLU(self.n_out_m1, 24)\n",
    "        self.n_out_m2 = d_emb * n_m2_toks\n",
    "        self.out_m2 = GLU(self.n_out_m2, 24)\n",
    "        \n",
    "        self.weights_init()\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr = lr)\n",
    "        self.loss = nn.HuberLoss()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.set_device(cuda)\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                #m.bias.data.fill_(0.01)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = rearrange(x, '... (s e) -> ... s e', e = self.d_emb)\n",
    "        cls_toks = repeat(self.cls_token, 's e -> b s e', b = x.size(0))\n",
    "        x = torch.cat((cls_toks, x), dim = 1)\n",
    "        x = x + self.pe #[:x.size(1)]\n",
    "        for enc in self.encoder:\n",
    "            x = enc(x)\n",
    "        #out = self.out(rearrange(x, 'i j k -> i (j k)'))\n",
    "        x = x[:, self.n_cls_toks]\n",
    "        x = rearrange(x, '... s e -> ... (s e)')\n",
    "        d = x[:, :self.n_out_d]\n",
    "        m1 = x[:, self.n_out_d : -self.n_out_m2]\n",
    "        m2 = x[:, -self.n_out_m2:]\n",
    "                \n",
    "        return self.out_d(d), self.out_m1(m1), self.out_m2(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5d074-09b7-4956-bc61-36e5b57e116e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
