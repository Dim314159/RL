{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5342f1d-9d04-41ee-889e-c1d3e7492918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import sys\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b02e4f-ecb6-40e4-a376-2f55bde7b6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a349853-79e1-4a25-aeb8-7e8005afb23f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e09bf62-2736-47ed-b6b8-5d997153a0df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## feed-forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3227d531-d0e1-42fa-95f1-44d6f31d699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice_embedder(nn.Module):\n",
    "    def __init__(self, d_emb):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(6, d_emb)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        #x = rearrange(x, '... i j -> ... (i j)')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "76354d2c-301d-4c07-a58a-8ec3719af7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table_embedder(nn.Module):\n",
    "    def __init__(self, drop):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(24, 16),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(16), \n",
    "            #nn.Dropout(drop),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(32), \n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(32, 24), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.LayerNorm(24))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "60324436-2c27-4a8d-b625-33de57ad2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Choose(nn.Module):\n",
    "    def __init__(self, d_emb, lr, drop):\n",
    "        super().__init__()\n",
    "        self.dice = Dice_embedder(d_emb)\n",
    "        self.table = Table_embedder(drop)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(24 + d_emb * 2, 32),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(32), \n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(16),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.LayerNorm(8),\n",
    "            nn.Linear(8, 2))\n",
    "    \n",
    "        self.weights_init()\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr = lr)\n",
    "        self.loss = nn.HuberLoss()\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward(self, t, d):\n",
    "        t = self.table(t)\n",
    "        d = self.dice(d)\n",
    "        td = torch.cat((t, d[0], d[1]))\n",
    "        out = self.out(td)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3f1b1cea-032f-471b-938f-544029600e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Move(nn.Module):\n",
    "    def __init__(self, d_emb, lr, drop):\n",
    "        super().__init__()\n",
    "        self.dice = Dice_embedder(d_emb)\n",
    "        self.table = Table(drop)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(24 + d_emb, 64),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(64), \n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(), \n",
    "            nn.LayerNorm(64),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.Linear(32, 24))\n",
    "                \n",
    "        self.weights_init()\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr = lr)\n",
    "        self.loss = nn.HuberLoss()\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward(self, t, d):\n",
    "        t = self.table(t)\n",
    "        d = self.dice(d)\n",
    "        td = torch.cat((t, d[0]))\n",
    "        out = self.out(td)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa1c6a-1db0-47eb-b58b-4561b12f0879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bb87219a-169e-4e8a-8c04-f458da64f4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5a29e088-149f-4db8-9d89-9742e2af2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_choose_w = Choose(4, 0.0001, 0.1)\n",
    "m_move1_w = Move(8, 0.0001, 0.1)\n",
    "m_move2_w = Move(8, 0.0001, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "11873579-4246-4f8c-aec2-26dbcba2cd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parameters: 3754\n",
      "num of parameters: 11392\n",
      "num of parameters: 11392\n"
     ]
    }
   ],
   "source": [
    "models = [m_choose_w, m_move1_w, m_move2_w]\n",
    "for m in models:\n",
    "    print('num of parameters:', sum(p.numel() for p in m.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d5b11-a46c-4ae9-9292-c996f401cad1",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d48f8ca-cddd-4327-89a6-9dd6a36ec7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, heads):\n",
    "        super().__init__()\n",
    "        self.d_hid = d_hid\n",
    "        self.heads = heads\n",
    "        self.dim_per_head = self.d_hid // self.heads\n",
    "        \n",
    "        self.qkv = nn.Linear(d_emb, self.d_hid * 3, bias = False)\n",
    "        \n",
    "        \n",
    "        self.unifyheads = nn.Linear(self.d_hid, d_emb)\n",
    "    \n",
    "    def self_attention(self, q, k, v):\n",
    "        scores = torch.einsum('...ij,...kj->...ik', q, k) / np.sqrt(self.dim_per_head)\n",
    "        scores = F.softmax(scores, dim = -1)\n",
    "        return torch.einsum('...ij,...jk->...ik', scores, v)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        qkv = self.qkv(x)\n",
    "        q = qkv[..., :self.d_hid]\n",
    "        k = qkv[..., self.d_hid : self.d_hid * 2]\n",
    "        v = qkv[..., self.d_hid * 2 :]\n",
    "            \n",
    "        q = rearrange(q, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        k = rearrange(k, '... i (h j) -> ... h i j', h = self.heads)\n",
    "        v = rearrange(v, '... i (h j) -> ... h i j', h = self.heads)\n",
    "                \n",
    "        scores = self.self_attention(q, k, v)\n",
    "        scores = rearrange(scores, '... h i j -> ... i (h j)').contiguous()\n",
    "                \n",
    "        return self.unifyheads(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5e0976-938f-423c-97c5-8117e837b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.out_size = out_size\n",
    "        self.linear = nn.Linear(in_size, out_size * 2)\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        #x = x[..., : self.out_size] * x[..., self.out_size :].sigmoid()\n",
    "        x = torch.einsum('...i, ...i->...i', [x[..., : self.out_size], x[..., self.out_size :].sigmoid()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7e144d-ee91-40ff-b73f-e82d7a3f4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_layer(nn.Module):\n",
    "    def __init__(self, d_emb, d_hid, hidden_mult, heads, enc_drop):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(enc_drop)\n",
    "        \n",
    "        self.mha = Multi_Head_Attention(d_emb, d_hid, heads)\n",
    "        self.norm_1 = nn.LayerNorm(d_emb)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_emb, hidden_mult * d_emb),\n",
    "            #nn.ReLU(),\n",
    "            #nn.GELU(),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_mult * d_emb, d_emb)\n",
    "        )\n",
    "        #self.ff = GLU(d_emb, d_emb)\n",
    "        \n",
    "        self.norm_2 = nn.LayerNorm(d_emb)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attended = self.mha(x)\n",
    "        x = attended + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_1(x)\n",
    "        fed_for = self.ff(x)\n",
    "        x = fed_for + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93b61d17-9a4b-42bc-93b0-163a8dc17557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, model_hp):\n",
    "        super().__init__()\n",
    "        self.epochs = 0\n",
    "        self.losses = []\n",
    "        \n",
    "        d_emb, seq_length, hidden_mult, order, enc_drop, d_toks, m_toks = model_hp\n",
    "        \n",
    "        self.sr_d_emb = np.sqrt(d_emb)\n",
    "        \n",
    "        self.dice_emb = nn.Embedding(6, d_emb)\n",
    "        self.table_emb = nn.Embedding(31, d_emb)\n",
    "        \n",
    "        self.cls_toks = d_toks + m_toks * 2\n",
    "        self.pe = nn.Parameter(torch.rand(seq_length + self.cls_toks, d_emb))\n",
    "        self.cls_token = nn.Parameter(torch.rand(self.cls_toks, d_emb))\n",
    "        \n",
    "        self.encoder = nn.ModuleList()\n",
    "        for d_hid, heads in order:\n",
    "            self.encoder.append(Encoder_layer(d_emb, d_hid, hidden_mult, heads, enc_drop))\n",
    "        \n",
    "        self.out = nn.Linear(self.cls_toks * d_emb, 52)\n",
    "                \n",
    "        self.weights_init()\n",
    "        \n",
    "        \n",
    "    def weights_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight, gain = nn.init.calculate_gain('relu'))\n",
    "                #m.bias.data.fill_(0.01)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        d = x[..., :2]\n",
    "        t = x[..., 2:] + 15\n",
    "        d = self.dice_emb(d)\n",
    "        t = self.table_emb(t)\n",
    "        #x = rearrange(x, '... (s e) -> ... s e', e = self.d_emb)\n",
    "        cls_toks = repeat(self.cls_token, 's e -> b s e', b = d.size(0))\n",
    "        x = torch.cat((cls_toks, t, d), dim = 1)\n",
    "        x = x * self.sr_d_emb + self.pe #[:x.size(1)]\n",
    "        for enc in self.encoder:\n",
    "            x = enc(x)\n",
    "        #out = self.out(rearrange(x, 'i j k -> i (j k)'))\n",
    "        x = x[:, :self.cls_toks]\n",
    "        x = rearrange(x, '... s e -> ... (s e)')\n",
    "        x = self.out(x)\n",
    "        d = x[:, :2]\n",
    "        m1 = x[:, 2 : -25]\n",
    "        m2 = x[:, -25:]\n",
    "        #return F.softmax(d, dim = -1), F.softmax(m1, dim = -1), F.softmax(m2, dim = -1)\n",
    "        return d, m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb16f4a-7436-4877-ba6a-5c852898423c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a3eb7c6-caba-459e-8e21-fcf8b14aaff6",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2711ca60-ec2c-44d2-8c5e-507d7116eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table():\n",
    "    def __init__(self):\n",
    "        self.phase = 0  # 0/1/2 -- game/house/done\n",
    "        self.state = np.zeros(24, dtype = int)\n",
    "        self.state[0] = 15\n",
    "        self.state[12] = -15\n",
    "        self.mine = {0}\n",
    "        self.his = {12}\n",
    "        self.home_cells = {6 : 18, 5 : 19, 4 : 20, 3 : 21, 2 : 22, 1 : 23}\n",
    "    \n",
    "    def check_phase(self):\n",
    "        if self.phase == 0:\n",
    "            condition = lambda x : x > 17\n",
    "            if all(condition(x) for x in self.mine):\n",
    "                self.phase = 1\n",
    "        elif self.phase == 1:\n",
    "            if not self.mine:\n",
    "                self.phase = 2\n",
    "    \n",
    "    def get_legal_actions(self, die, flag_head):\n",
    "        die += 1\n",
    "        legal_actions = np.zeros(25)\n",
    "        if self.phase == 1:\n",
    "            flag_out = True\n",
    "            tempo_actions = []\n",
    "            for p in range(6, die - 1, -1):\n",
    "                if self.home_cells[p] in self.mine:\n",
    "                    tempo_actions.append(p)\n",
    "                    flag_out = False\n",
    "            if flag_out:\n",
    "                legal_actions[list(self.mine)] = 1\n",
    "            else:\n",
    "                for p in tempo_actions:\n",
    "                    if (self.home_cells[p] + die > 23) or (self.home_cells[p - die] not in self.his):\n",
    "                        legal_actions[self.home_cells[p]] = 1\n",
    "        elif self.phase == 0:\n",
    "            for p in self.mine:\n",
    "                destination = p + die\n",
    "                if (destination < 24) and (destination not in self.his):\n",
    "                    if destination < 12 and destination not in self.mine:\n",
    "                        new_mine = self.mine | {destination}\n",
    "                        if not self.check_mars(new_mine):\n",
    "                            legal_actions[p] = 1\n",
    "                    else:\n",
    "                        legal_actions[p] = 1\n",
    "            if flag_head:\n",
    "                legal_actions[0] = 0\n",
    "        return legal_actions.astype(bool)\n",
    "    \n",
    "    def check_mars(self, new_mine):\n",
    "        n = 6\n",
    "        mars_end = 0\n",
    "        for i in range(7):\n",
    "            if all(j in new_mine for j in range(i, i + n)):\n",
    "                mars_end = i + n\n",
    "        if mars_end:\n",
    "            for i in range(mars_end, 12):\n",
    "                if i in self.his:\n",
    "                    return False\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def update(self, action, die, me):\n",
    "        die += 1\n",
    "        if me:\n",
    "            destination = action + die\n",
    "            self.state[action] -= 1\n",
    "            if self.state[action] < 1:\n",
    "                self.mine.remove(action)\n",
    "            if destination < 24:\n",
    "                self.state[destination] += 1\n",
    "                self.mine.add(destination)\n",
    "        else:\n",
    "            destination = action + die\n",
    "            action = (action + 12) % 24\n",
    "            self.state[action] += 1\n",
    "            if self.state[action] > -1:\n",
    "                self.his.remove(action)\n",
    "            if destination < 24:\n",
    "                destination = (destination + 12) % 24\n",
    "                self.state[destination] -= 1\n",
    "                self.his.add(destination)\n",
    "    \n",
    "    def print_table(self):\n",
    "        row_format = '{:>6}' * 13\n",
    "        print(row_format.format('', *self.state[11::-1]))\n",
    "        print(row_format.format('', *self.state[12:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "29e716d5-b09d-4207-96cd-cafbded14e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, model, model_hp, device):\n",
    "        super().__init__()\n",
    "        self.q_network = model(model_hp).to(device)\n",
    "        self.t_network = model(model_hp).to(device)\n",
    "        self.t_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.table = Table()\n",
    "        self.flag_first_turn = True\n",
    "        self.dice = None\n",
    "        #self.flag_done = False\n",
    "        self.flag_winner = False\n",
    "        \n",
    "        self.epsilon = 0.5\n",
    "        self.memory_size = 2**13\n",
    "        self.buffer_size = 2**7\n",
    "        self.rep_memory = deque(maxlen = self.memory_size) #[2 dice,  24 table cells], size 26\n",
    "        self.act_memory = deque(maxlen = self.memory_size) #[die, move1, move1]\n",
    "        self.rew_memory = deque(maxlen = self.memory_size)\n",
    "        self.games_played = 0\n",
    "    \n",
    "    def refresh(self, reset = False):\n",
    "        self.table = Table()\n",
    "        self.flag_first_turn = True\n",
    "        self.dice = None\n",
    "        #self.flag_done = False\n",
    "        self.flag_winner = False\n",
    "        if reset:\n",
    "            self.rep_memory = []\n",
    "            self.act_memory = []\n",
    "            self.rew_memory = []\n",
    "    \n",
    "    def roll(self):\n",
    "        self.dice = list(np.random.randint(6, size = 2))\n",
    "    \n",
    "    def update_rep_memory(self):\n",
    "        self.rep_memory.append(np.concatenate((self.dice , self.table.state)))\n",
    "    def update_act_memory(self, d, m1, m2):\n",
    "        self.act_memory.append([d, m1, m2])\n",
    "    def update_rew_memory(self):\n",
    "        self.rew_memory.append(-1)\n",
    "    \n",
    "    def memory_not_full(self):\n",
    "        return len(self.rew_memory) != self.memory_size\n",
    "        \n",
    "    def num_parameters(self):\n",
    "        n = sum(p.numel() for p in self.q_network.parameters() if p.requires_grad)\n",
    "        print('number of parameters:', n)\n",
    "        \n",
    "    def calculate(self):\n",
    "        x = torch.LongTensor(self.rep_memory[-1]).to(device)\n",
    "        x = x.unsqueeze(0)\n",
    "        # d = x[..., :2]\n",
    "        # t = x[..., 2:] + 15\n",
    "        self.q_network.eval()\n",
    "        with torch.no_grad():\n",
    "            d, m1, m2 = self.q_network(x)\n",
    "        return d.detach().cpu()[0], m1.detach().cpu()[0], m2.detach().cpu()[0]\n",
    "    \n",
    "    def print_replay_memory(self, num_turns):\n",
    "        row_format = '{:>6}' * 13\n",
    "        for i in range(len(self.rep_memory) - num_turns , len(self.rep_memory)):\n",
    "            print(row_format.format('', *self.rep_memory[i][13:1:-1]))\n",
    "            print(row_format.format('', *self.rep_memory[i][14:]))\n",
    "            print(self.rep_memory[i][:2] + 1)\n",
    "            print(self.act_memory[i])\n",
    "            print(self.rew_memory[i])\n",
    "            print()\n",
    "    \n",
    "    def train_the_agent(self, epochs, gamma, update_interval):\n",
    "        self.q_network.train()\n",
    "        self.t_network.eval()\n",
    "        for epoch in range(epochs):\n",
    "            indices = np.random.choice(range(self.memory_size - 1), self.buffer_size, replace = False)\n",
    "            # Retrieve corresponding elements using the sampled indices\n",
    "            states = [self.rep_memory[i] for i in indices]\n",
    "            states = torch.tensor(np.vstack(states)).to(device)\n",
    "            next_states = [self.rep_memory[i + 1] for i in indices]\n",
    "            next_states = torch.tensor(np.vstack(next_states)).to(device)\n",
    "            actions = [self.act_memory[i] for i in indices]\n",
    "            actions = torch.tensor(actions).to(device)\n",
    "            rewards = [self.rew_memory[i] for i in indices]\n",
    "            rewards = torch.tensor(rewards).to(device)\n",
    "            done = torch.eq(rewards, -1).int().to(device)\n",
    "\n",
    "            d, m1, m2 = self.q_network(states)\n",
    "            q_d_values = d.gather(1, actions[:, 0].unsqueeze(1)).squeeze(1)\n",
    "            q_m1_values = m1.gather(1, actions[:, 1].unsqueeze(1)).squeeze(1)\n",
    "            q_m2_values = m2.gather(1, actions[:, 1].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            d, m1, m2 = self.t_network(next_states)\n",
    "            t_d_values = rewards + done * gamma * d.max(1)[0]\n",
    "            t_m1_values = rewards + done * gamma * m1.max(1)[0]\n",
    "            t_m2_values = rewards + done * gamma * m2.max(1)[0]\n",
    "\n",
    "            loss = self.criterion(torch.cat((q_d_values, q_m1_values, q_m2_values)), \n",
    "                                  torch.cat((t_d_values, t_m1_values, t_m2_values)))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if epoch % update_interval == 0:\n",
    "                self.t_network.load_state_dict(self.q_network.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "553e2dfd-e5fb-4e03-b511-ea4a57963e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_h():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.table = Table()\n",
    "        self.flag_first_turn = True\n",
    "        self.dice = None\n",
    "        self.flag_winner = False\n",
    "        \n",
    "        self.memory_size = 2**13\n",
    "        \n",
    "        self.rep_memory = deque(maxlen = self.memory_size) #[2 dice,  24 table cells], size 26\n",
    "        self.act_memory = deque(maxlen = self.memory_size) #[die, move1, move1]\n",
    "        self.rew_memory = deque(maxlen = self.memory_size)\n",
    "        self.games_played = 0\n",
    "    \n",
    "    def refresh(self, reset = False):\n",
    "        self.table = Table()\n",
    "        self.flag_first_turn = True\n",
    "        self.dice = None\n",
    "        self.flag_winner = False\n",
    "        if reset:\n",
    "            self.rep_memory = []\n",
    "            self.act_memory = []\n",
    "            self.rew_memory = []\n",
    "    \n",
    "    def roll(self):\n",
    "        self.dice = list(np.random.randint(6, size = 2))\n",
    "    \n",
    "    def update_rep_memory(self):\n",
    "        self.rep_memory.append(np.concatenate((self.dice , self.table.state)))\n",
    "    def update_act_memory(self, d, m1, m2):\n",
    "        self.act_memory.append([d, m1, m2])\n",
    "    def update_rew_memory(self):\n",
    "        self.rew_memory.append(-1)\n",
    "    \n",
    "    def memory_not_full(self):\n",
    "        return len(self.rew_memory) != self.memory_size\n",
    "        \n",
    "    def print_replay_memory(self, num_turns):\n",
    "        row_format = '{:>6}' * 13\n",
    "        for i in range(len(self.rep_memory) - num_turns , len(self.rep_memory)):\n",
    "            print(row_format.format('', *self.rep_memory[i][13:1:-1]))\n",
    "            print(row_format.format('', *self.rep_memory[i][14:]))\n",
    "            print(self.rep_memory[i][:2] + 1)\n",
    "            print(self.act_memory[i])\n",
    "            print(self.rew_memory[i])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "484edaec-f514-4c58-84de-fe8688dc1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn(agent, ag, flag_print = False):\n",
    "    epsilon = agent.epsilon\n",
    "    if flag_print:\n",
    "        agent.table.print_table()\n",
    "        epsilon = None\n",
    "    if agent.table.phase != 2:\n",
    "        agent.roll() # roll the dice\n",
    "        if flag_print:\n",
    "            print(' ' * 36, agent.dice[0] + 1, agent.dice[1] + 1)\n",
    "        else:\n",
    "            agent.update_rep_memory()\n",
    "        d, m1, m2 = agent.calculate()\n",
    "        if epsilon is not None:\n",
    "            if np.random.random() < agent.epsilon:\n",
    "                d = np.random.choice(dice_index)\n",
    "            else:\n",
    "                d = F.softmax(d, dim = -1).numpy()\n",
    "                d = np.random.choice(dice_index, p = d)\n",
    "        else:\n",
    "            d = F.softmax(d, dim = -1).numpy()\n",
    "            d = np.argmax(d)\n",
    "        d1 = agent.dice.pop(d)\n",
    "        d2 = agent.dice[0]\n",
    "        flag_head = False\n",
    "        mask = agent.table.get_legal_actions(d1, flag_head)\n",
    "        if mask.sum() > 0:\n",
    "            if epsilon is not None:\n",
    "                if np.random.random() < agent.epsilon:\n",
    "                    m1 = np.random.choice(actions_index[mask])\n",
    "                else:\n",
    "                    m1 = F.softmax(m1[mask], dim = -1).numpy()\n",
    "                    m1 = np.random.choice(actions_index[mask], p = m1)\n",
    "            else:\n",
    "                m1 = F.softmax(m1[mask], dim = -1).numpy()\n",
    "                m1 = np.argmax(m1)\n",
    "                m1 = actions_index[mask][m1]\n",
    "            agent.table.update(m1, d1, True)\n",
    "            ag.table.update(m1, d1, False)\n",
    "            agent.table.check_phase()\n",
    "            if flag_print:\n",
    "                print('1st', m1, d1 + 1)\n",
    "                agent.table.print_table()\n",
    "        else:\n",
    "            m1 = 24\n",
    "            if flag_print:\n",
    "                print('no legal moves')\n",
    "        if agent.flag_first_turn:\n",
    "            agent.flag_first_turn = False\n",
    "        elif m1 == 0:\n",
    "            flag_head = True\n",
    "        mask = agent.table.get_legal_actions(d2, flag_head)\n",
    "        if mask.sum() > 0:\n",
    "            if epsilon is not None:\n",
    "                if np.random.random() < agent.epsilon:\n",
    "                    m2 = np.random.choice(actions_index[mask])\n",
    "                else:\n",
    "                    m2 = F.softmax(m2[mask], dim = -1).numpy()\n",
    "                    m2 = np.random.choice(actions_index[mask], p = m2)\n",
    "            else:\n",
    "                m2 = F.softmax(m2[mask], dim = -1).numpy()\n",
    "                m2 = np.argmax(m2)\n",
    "                m2 = actions_index[mask][m2]\n",
    "            agent.table.update(m2, d2, True)\n",
    "            ag.table.update(m2, d2, False)\n",
    "            agent.table.check_phase()\n",
    "            if flag_print:\n",
    "                print('2nd', m2, d2 + 1)\n",
    "                agent.table.print_table()\n",
    "        else:\n",
    "            m2 = 24\n",
    "            if flag_print:\n",
    "                print('no legal moves')\n",
    "        if not flag_print:\n",
    "            agent.update_act_memory(d, m1, m2)\n",
    "            agent.update_rew_memory()\n",
    "        if agent.table.phase == 2:\n",
    "            #agent.flag_done = True\n",
    "            agent.flag_winner = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e7000c5c-3f7b-4b9f-9724-885e6afbb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def session(ag_1, ag_2):\n",
    "    ag_1.refresh(reset = False)\n",
    "    ag_2.refresh(reset = False)\n",
    "    while True:\n",
    "        turn(ag_1, ag_2)\n",
    "        if ag_1.flag_winner:\n",
    "            ag_1.rew_memory[-1] = 20\n",
    "            ag_2.rew_memory[-1] = -20\n",
    "            break\n",
    "        turn(ag_2, ag_1)\n",
    "        if ag_2.flag_winner:\n",
    "            ag_2.rew_memory[-1] = 20\n",
    "            ag_1.rew_memory[-1] = -20\n",
    "            break\n",
    "    ag_1.games_played += 1\n",
    "    ag_2.games_played += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "057144a4-f170-4277-8edc-324618b3e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_the_replay_memory(ag_1, ag_2):\n",
    "    start_time = dt.now()\n",
    "    while ag_1.memory_not_full() or ag_2.memory_not_full():\n",
    "        session(ag_1, ag_2)\n",
    "        session(ag_2, ag_1)\n",
    "        if ag_1.games_played % 10 == 0:\n",
    "            elapsed = dt.now() - start_time\n",
    "            secs = elapsed.seconds\n",
    "            printout = '\\rsessions: %d, ag_1: %d, ag_2: %d, %02d:%02d:%02d:%02d'\n",
    "            sys.stdout.write(printout % (ag_1.games_played, len(ag_1.rew_memory), len(ag_2.rew_memory), \n",
    "                                         elapsed.days, secs // 3600, secs // 60 % 60, secs % 60))\n",
    "            sys.stdout.flush()\n",
    "    sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0100eccd-b61b-4039-bff1-921655ccc819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_train(ag_1, ag_2, num_sessions, train_interval, epochs, gamma, update_interval):\n",
    "    start_time = dt.now()\n",
    "    ns = num_sessions // 2\n",
    "    for i in range(ns):\n",
    "        if i % train_interval == 0:\n",
    "            ag_1.train_the_agent(epochs, gamma, update_interval)\n",
    "            ag_1.train_the_agent(epochs, gamma, update_interval)\n",
    "        session(ag_1, ag_2)\n",
    "        session(ag_2, ag_1)\n",
    "        \n",
    "        elapsed = dt.now() - start_time\n",
    "        ratio = i / ns\n",
    "        secs = elapsed.seconds\n",
    "        printout = '\\r[%-16s] %d%%, sessions: %d, %02d:%02d:%02d:%02d'\n",
    "        sys.stdout.write(printout % ('='*round(16 * ratio), round(100 * ratio), i * 2, \n",
    "                                     elapsed.days, secs // 3600, secs // 60 % 60, secs % 60))\n",
    "        sys.stdout.flush()\n",
    "    sys.stdout.write('\\n')\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "455388d3-15be-4753-ae99-592e91883b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_a(agent, ag):\n",
    "    print(' ' * 36, 'Agent')\n",
    "    agent.table.print_table()\n",
    "    if agent.table.phase != 2:\n",
    "        agent.roll() # roll the dice\n",
    "        print(' ' * 36, agent.dice[0] + 1, agent.dice[1] + 1)\n",
    "        d, m1, m2 = agent.calculate()\n",
    "        d = F.softmax(d, dim = -1).numpy()\n",
    "        d = np.argmax(d)\n",
    "        d1 = agent.dice.pop(d)\n",
    "        d2 = agent.dice[0]\n",
    "        flag_head = False\n",
    "        mask = agent.table.get_legal_actions(d1, flag_head)\n",
    "        if mask.sum() > 0:\n",
    "            m1 = F.softmax(m1[mask], dim = -1).numpy()\n",
    "            m1 = np.argmax(m1)\n",
    "            m1 = actions_index[mask][m1]\n",
    "            agent.table.update(m1, d1, True)\n",
    "            ag.table.update(m1, d1, False)\n",
    "            agent.table.check_phase()\n",
    "            print('1st', m1, d1 + 1)\n",
    "            agent.table.print_table()\n",
    "        else:\n",
    "            m1 = 24\n",
    "            print('no legal moves')\n",
    "        if agent.flag_first_turn:\n",
    "            agent.flag_first_turn = False\n",
    "        elif m1 == 0:\n",
    "            flag_head = True\n",
    "        mask = agent.table.get_legal_actions(d2, flag_head)\n",
    "        if mask.sum() > 0:\n",
    "            m2 = F.softmax(m2[mask], dim = -1).numpy()\n",
    "            m2 = np.argmax(m2)\n",
    "            m2 = actions_index[mask][m2]\n",
    "            agent.table.update(m2, d2, True)\n",
    "            ag.table.update(m2, d2, False)\n",
    "            agent.table.check_phase()\n",
    "            print('2nd', m2, d2 + 1)\n",
    "            agent.table.print_table()\n",
    "        else:\n",
    "            m2 = 24\n",
    "            print('no legal moves')\n",
    "        if agent.table.phase == 2:\n",
    "            agent.flag_winner = True\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "86018e07-1be5-4213-b49e-10fd698e4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_h(agent, ag):\n",
    "    print(' ' * 36, 'Human')\n",
    "    agent.table.print_table()\n",
    "    if agent.table.phase != 2:\n",
    "        agent.roll() # roll the dice\n",
    "        print(' ' * 36, agent.dice[0] + 1, agent.dice[1] + 1)\n",
    "        d = int(input('Pick your die: '))\n",
    "        d1 = agent.dice.pop(d)\n",
    "        d2 = agent.dice[0]\n",
    "        flag_head = False\n",
    "        mask = agent.table.get_legal_actions(d1, flag_head)\n",
    "        if mask.sum() > 0:\n",
    "            while True:\n",
    "                m1 = int(input('Move your piece: '))\n",
    "                if mask[m1]:\n",
    "                    agent.table.update(m1, d1, True)\n",
    "                    ag.table.update(m1, d1, False)\n",
    "                    agent.table.check_phase()\n",
    "                    print('1st', m1, d1 + 1)\n",
    "                    agent.table.print_table()\n",
    "                    break\n",
    "        else:\n",
    "            print('no legal moves')\n",
    "        if agent.flag_first_turn:\n",
    "            agent.flag_first_turn = False\n",
    "        elif m1 == 0:\n",
    "            flag_head = True\n",
    "        mask = agent.table.get_legal_actions(d2, flag_head)\n",
    "        if mask.sum() > 0:\n",
    "            while True:\n",
    "                m2 = int(input('Move your piece: '))\n",
    "                if mask[m2]:\n",
    "                    agent.table.update(m2, d2, True)\n",
    "                    ag.table.update(m2, d2, False)\n",
    "                    agent.table.check_phase()\n",
    "                    print('2nd', m2, d2 + 1)\n",
    "                    agent.table.print_table()\n",
    "                    break\n",
    "        else:\n",
    "            print('no legal moves')\n",
    "        if agent.table.phase == 2:\n",
    "            agent.flag_winner = True\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "642f9951-e729-45af-9056-6d569d9b4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_h(ag, hum, h_first = True):\n",
    "    ag.refresh(reset = False)\n",
    "    hum.refresh(reset = False)\n",
    "    if h_first:\n",
    "        while True:\n",
    "            turn_h(hum, ag)\n",
    "            if hum.flag_winner:\n",
    "                ag.rew_memory[-1] = -20\n",
    "                break\n",
    "            turn_a(ag, hum)\n",
    "            if ag.flag_winner:\n",
    "                ag.rew_memory[-1] = 20\n",
    "                break\n",
    "    else:\n",
    "        while True:\n",
    "            turn_a(ag, hum)\n",
    "            if ag.flag_winner:\n",
    "                ag.rew_memory[-1] = 20\n",
    "                break\n",
    "            turn_h(hum, ag)\n",
    "            if hum.flag_winner:\n",
    "                ag.rew_memory[-1] = -20\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a18b7c-1375-4648-aebc-006daabf843e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1250feee-0bf2-4414-ab2e-0a65353dc9c5",
   "metadata": {},
   "source": [
    "# Create agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54e7d88f-baca-4272-8d35-e379898b5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "cuda_core = 0\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda_core)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bdcbcef2-7b40-49f0-a5ff-3e69f8700fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c54a6b88-03c6-448e-bfd2-c676e5568abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_index = np.arange(2)\n",
    "actions_index = np.arange(25)\n",
    "\n",
    "d_emb = 8\n",
    "seq_length = 26\n",
    "hidden_mult = 2\n",
    "# order = [(128, 8), (128, 8), \n",
    "#          (64, 4), (64, 4), \n",
    "#          (64, 2), (64, 2), \n",
    "#          (32, 1), (32, 1)]\n",
    "order = [(32, 4), (32, 4), (32, 2), (32, 2), (32, 1), (32, 1)]\n",
    "#heads_order = [1] * 12\n",
    "enc_drop = 0 # 0.05  # 0.005\n",
    "d_toks = 1\n",
    "m_toks = 2\n",
    "\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a0b3ca77-4eef-4e63-971c-ab825baaa0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_hp = d_emb, seq_length, hidden_mult, order, enc_drop, d_toks, m_toks\n",
    "model = Transformer\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr = lr)\n",
    "# criterion = nn.HuberLoss()\n",
    "#print('num of parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "30aab82b-f4a4-4a96-87f0-938367058bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_1 = Agent(model, model1_hp, device)\n",
    "ag_1.optimizer = torch.optim.AdamW(ag_1.q_network.parameters(), lr = lr)\n",
    "ag_1.criterion = nn.MSELoss()\n",
    "ag_2 = Agent(model, model1_hp, device)\n",
    "ag_2.optimizer = torch.optim.AdamW(ag_2.q_network.parameters(), lr = lr)\n",
    "ag_2.criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82602821-c0f6-49f2-ab5a-733031d131c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a73974a3-d916-485f-aabf-f22e16810bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessions: 140, ag_1: 7786, ag_2: 7802, 00:00:01:02\n"
     ]
    }
   ],
   "source": [
    "# start\n",
    "fill_the_replay_memory(ag_1, ag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3937e216-2eec-4e16-ad28-7ad2cbd4ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sessions = 1000\n",
    "train_interval = 10\n",
    "epochs = 2**7\n",
    "gamma = 0.98\n",
    "update_interval = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "56e17aa8-b771-4c48-ae71-87889c437f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================] 100%, sessions: 998, 00:00:19:12\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "collect_and_train(ag_1, ag_2, num_sessions, train_interval, epochs, gamma, update_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "989545aa-e4b3-43aa-b0c9-1dd2fb0227fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_1.epsilon = 0\n",
    "ag_2.epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "599f69ab-8a8c-47b5-83d8-1d6687883e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ag_1.refresh(reset = False)\n",
    "# ag_2.refresh(reset = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2ea79a3a-755c-4ad7-af8e-50ef66b6ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('agent 1')\n",
    "# turn(ag_1, ag_2, flag_print = True)\n",
    "# print('\\nagent 2')\n",
    "# turn(ag_2, ag_1, flag_print = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fba8e-ba29-4c31-9d3d-f844b3c24828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fc3bc21-d69b-4895-9a05-8a6438c57efc",
   "metadata": {},
   "source": [
    "# H Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b91bbe1a-0184-431b-89bb-11efe7e4112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hum = Agent_h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abe579-667b-4e3a-8340-68cd149b1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_h(ag_1, hum, h_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8964c1-46f7-4c45-8eb4-39319014b7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052cd39e-9cf6-45a7-8f85-bc2c5aa1cb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b7fd3024-3e98-4355-bed4-34bd0cd59213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d0daee97-f0bf-4071-8782-1d885106070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = input('Pick your number by index: ')\n",
    "index = int(input_str) - 1\n",
    "\n",
    "# Clear the output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494a910-a47a-4aef-8baf-f749ac8d017f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4495eed-76da-4224-85df-90026ec41f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c42cc-5038-440b-914c-f40150443be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5404201-11ea-4dee-97e9-3f6c16b45b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd88a6-2147-40c3-a9b5-15a07d19d84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8224401-ecb2-45d5-974b-29fd08d94168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42d2ef-b78c-4345-a142-f142e175ea04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e404d60-067f-47f4-ae65-e309e73b822a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a4990-bd62-4f55-b073-3d411e182abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9dafa-70b1-4014-a4f1-5ae42598bbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c580986-5ec6-456e-9d2d-4663a47d242e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c60e6-a05e-4c2a-8e00-9d630254f8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff53134-1635-4b4f-a781-fadc532bc317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429b5be-ae90-40e7-a014-d6c566018f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723fd1f-567f-4c1c-92c8-c5e89537144f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc388c9-653e-4bb1-811c-d8ba146cabaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c7a42-9562-4fbf-a755-7a4e3b384ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d3368-902f-4dc3-9b1d-4ea3c25f8d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534ab4c-5c46-4cd9-93ed-c0db79a7bc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400616ef-78c5-4c49-83ff-4b53b1530f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a974d4-2699-4781-a157-8e473f9ff3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc5fea-6b70-4bc4-a264-de25584ae729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91bdd77-d537-4798-bcd4-ac0baba40bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7a6d5-29de-4ac8-9eaa-69b6ecb43cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3b9e46d-ac2d-4dba-a6bb-27b5d923dc39",
   "metadata": {},
   "source": [
    "# WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b51751-1e12-4a20-8c2f-f6246a8d83de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbe88c-1500-4f61-ad66-f5753cc255c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab17e301-8787-4dba-b659-5b3b4c2b1e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3479d83c-b71a-40b1-9cfb-aafcce8a1639",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2117b-f6ca-4df6-bac2-5157a3f5b463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5d074-09b7-4956-bc61-36e5b57e116e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
